{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Baselines - Running the experiments\n",
    "\n",
    "This scripts takes very long to run (possibly days if not parralelized).\n",
    "This is mostly due to the local and univariate models, which need to be trained for each time series\n",
    "individually. The global models are trained on all time series at once and are therefore much, much faster to evaluate.\n",
    "Note, that in order to speed up the evaluation of the local models, we only evaluate these models them on the first `evaluate_first_n_companies` companies.\n",
    "\n",
    "Also, this notebook will prompt you for an *Weights and Biases* API key. You can get one for free at https://wandb.ai.\n",
    "Alternatively, you can run the notebook without Weights and Biases by commenting out `wandb.login()` and by passing `use_logger=False` to `ModelEvaluator()`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import pickle\n",
    "from argparse import ArgumentParser\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from sortedcontainers import SortedDict\n",
    "from darts import TimeSeries\n",
    "from darts.models.forecasting.forecasting_model import ForecastingModel\n",
    "import wandb\n",
    "from rich.progress import track\n",
    "\n",
    "from proprietary_data import CompanyFundamentalsKind, ALL_FEATURE_NAMES, KEY_FEATURE_NAMES\n",
    "from proprietary_data.darts import (\n",
    "    load_company_fundamentals_as_darts_time_series,\n",
    "    TimeSeriesContainer,\n",
    "    generate_splits,\n",
    ")\n",
    "from forecasting_cfs.eval_model import ModelEvaluator, ForecastingResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we are logged in to wandb\n",
    "assert wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darts is extremely noisy\n",
    "logging.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interactive():\n",
    "    import __main__ as main\n",
    "\n",
    "    return not hasattr(main, \"__file__\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not is_interactive():\n",
    "        raise RuntimeError(\n",
    "            \"You need to indent everything below this by one after exporting to a standalone file\"\n",
    "        )\n",
    "\n",
    "\n",
    "TARGET_ALL_FEATURES = False\n",
    "USE_STATIC_COVARIATES = True\n",
    "USE_REVIN = True\n",
    "NORMALIZE_LOCAL_MODELS = True\n",
    "UNCERTAINTY = True\n",
    "\n",
    "# We do not provide a seasonality guess since even for quarterly data, the seasonality is not always 4\n",
    "# as automatic seasonality detection indicates\n",
    "\n",
    "HORIZON_LOOKBACK = 12  # 16 would also be fine\n",
    "HORIZON_FORECAST = 4\n",
    "STRIDE = 1\n",
    "WINDOW_MODE = \"expanding\"\n",
    "\n",
    "only_from_to: None | tuple[int, int] = None\n",
    "\n",
    "\n",
    "if not is_interactive():\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--use_all_features\", default=TARGET_ALL_FEATURES, action=\"store_true\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-use_all_features\", dest=\"use_all_features\", action=\"store_false\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_static_covariates\", default=USE_STATIC_COVARIATES, action=\"store_true\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-use_static_covariates\", dest=\"use_static_covariates\", action=\"store_false\"\n",
    "    )\n",
    "    parser.add_argument(\"--use_revin\", default=USE_REVIN, action=\"store_true\")\n",
    "    parser.add_argument(\"--no-use_revin\", dest=\"use_revin\", action=\"store_false\")\n",
    "    parser.add_argument(\"--use_uncertainty\", default=UNCERTAINTY, action=\"store_true\")\n",
    "    parser.add_argument(\n",
    "        \"--no-use_uncertainty\", dest=\"use_uncertainty\", action=\"store_false\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--lookback\", type=int, default=HORIZON_LOOKBACK)\n",
    "    parser.add_argument(\"--forecast\", type=int, default=HORIZON_FORECAST)\n",
    "    parser.add_argument(\"--stride\", type=int, default=STRIDE)\n",
    "    parser.add_argument(\n",
    "        \"--window\", default=WINDOW_MODE, choices=[\"sliding\", \"expanding\"]\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--limit\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "        help=\"Limit the range in index steps. Format: `from,to`, where the latter is exclusive.\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    TARGET_ALL_FEATURES = args.use_all_features\n",
    "    USE_STATIC_COVARIATES = args.use_static_covariates\n",
    "    USE_REVIN = args.use_revin\n",
    "    UNCERTAINTY = args.use_uncertainty\n",
    "\n",
    "    HORIZON_LOOKBACK = args.lookback\n",
    "    HORIZON_FORECAST = args.forecast\n",
    "    STRIDE = args.stride\n",
    "    WINDOW_MODE = args.window\n",
    "\n",
    "    if args.limit:\n",
    "        only_from_to = tuple(map(int, args.limit.split(\",\")))\n",
    "        assert len(only_from_to) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"DEBUG-statics_{USE_STATIC_COVARIATES}-revin_{USE_REVIN}-stride{STRIDE}_lb{HORIZON_LOOKBACK}-{WINDOW_MODE}-uq_{UNCERTAINTY}\"\n",
    "OUT_PATH = Path(\"forecast_baselines\") / run_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = ALL_FEATURE_NAMES if TARGET_ALL_FEATURES else KEY_FEATURE_NAMES\n",
    "COVARIATES = [item for item in ALL_FEATURE_NAMES if item not in TARGETS]\n",
    "\n",
    "darts_ts: TimeSeriesContainer = load_company_fundamentals_as_darts_time_series(\n",
    "    kind=CompanyFundamentalsKind.Normalized,\n",
    "    subset=False,\n",
    "    min_length=\"max\",  # only use complete sequences for simplicity when comparing to other models\n",
    "    include_static_metadata=USE_STATIC_COVARIATES,\n",
    "    static_metadata_columns=[\"GICS_sector\"],\n",
    "    target_columns=TARGETS,\n",
    "    covariate_columns=COVARIATES,\n",
    "    n_jobs=4,  # Increasing this won't help much\n",
    ").one_hot_encode_statics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate by splitting the 40 quarterly datapoints into several folds.\n",
    "We do this to evaluate the models on different time periods, which is important for forecasting, since the dynamics can change drastically over time.\n",
    "In the extreme cases, this can be due to financial cirses, conflicts, ... but also just more stublte effects the interplay of debt vs. equity financing and reporting bahviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a dummy check. Also, we need twice the HORIZON_FORECAST for training + testing\n",
    "assert HORIZON_LOOKBACK + 2 * HORIZON_FORECAST <= darts_ts.targets[0].n_timesteps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate many slices of the data (depending on the number of time steps `darts_ts.targets[0].n_timesteps` and the `stride`), which we will use for cross-validation.\n",
    "\n",
    "## Enumerate Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import (\n",
    "    NBEATSModel,\n",
    "    ARIMA,\n",
    "    VARIMA,\n",
    "    StatsForecastAutoARIMA,\n",
    "    StatsForecastAutoTheta,\n",
    "    Prophet,\n",
    "    RandomForest,\n",
    "    LinearRegressionModel,\n",
    "    RNNModel,\n",
    "    TCNModel,\n",
    "    TransformerModel,\n",
    "    TFTModel,\n",
    "    DLinearModel,\n",
    "    NLinearModel,\n",
    "    NaiveMean,\n",
    "    NaiveMovingAverage,\n",
    "    NHiTSModel,\n",
    "    TiDEModel,\n",
    "    BlockRNNModel,\n",
    ")\n",
    "from darts.models.forecasting.forecasting_model import GlobalForecastingModel\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "from forecasting_cfs.chronos import ChronosDartsWrapper\n",
    "from forecasting_cfs.xlstm_mixer import xLSTMMixer\n",
    "\n",
    "likelihood = \"quantile\" if UNCERTAINTY else None\n",
    "likelihood_model = QuantileRegression if UNCERTAINTY else (lambda: None)\n",
    "\n",
    "\n",
    "# See https://arxiv.org/pdf/1803.09820.pdf\n",
    "# See https://unit8co.github.io/darts/examples/18-TiDE-examples.html\n",
    "def my_early_stopper():\n",
    "    return EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=3,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "\n",
    "\n",
    "def common_torch_wo_dropout():\n",
    "    return dict(\n",
    "        pl_trainer_kwargs=dict(\n",
    "            accelerator=\"auto\",\n",
    "            devices=\"auto\",\n",
    "            gradient_clip_val=1.0,\n",
    "            callbacks=[my_early_stopper()],\n",
    "        ),\n",
    "        optimizer_cls=optim.AdamW,\n",
    "        optimizer_kwargs=dict(lr=0.0001, weight_decay=0.01),\n",
    "        batch_size=64,\n",
    "        n_epochs=100,\n",
    "    )\n",
    "\n",
    "\n",
    "def common_torch():\n",
    "    return dict(**common_torch_wo_dropout(), dropout=0.1)\n",
    "\n",
    "\n",
    "def make_models() -> dict[str, ForecastingModel]:\n",
    "    models: dict[str, ForecastingModel] = {\n",
    "        \"Mean\": NaiveMean(),\n",
    "        \"ARMean(1)\": NaiveMovingAverage(input_chunk_length=1),\n",
    "        \"ARMean(4)\": NaiveMovingAverage(input_chunk_length=4),\n",
    "        \"ARMA(1,1)\": ARIMA(p=1, d=0, q=1, trend=\"ct\"),\n",
    "        \"ARMA(4,4)\": ARIMA(p=4, d=0, q=4, trend=\"ct\"),\n",
    "        \"ARIMA(4,1,4)\": ARIMA(p=4, d=1, q=4, trend=\"t\"),\n",
    "        \"VARIMA(4,0,4)\": VARIMA(p=4, d=0, q=4, trend=\"ct\"),\n",
    "        \"VARIMA(4,1,4)\": VARIMA(p=4, d=1, q=4),\n",
    "        \"AutoARIMA\": StatsForecastAutoARIMA(),\n",
    "        \"AutoTheta\": StatsForecastAutoTheta(),\n",
    "        \"Prophet\": Prophet(),\n",
    "        # ############################################\n",
    "        \"Linear Reg.\": LinearRegressionModel(\n",
    "            lags=HORIZON_LOOKBACK,\n",
    "            output_chunk_length=HORIZON_FORECAST,\n",
    "            lags_past_covariates=(\n",
    "                HORIZON_LOOKBACK if not TARGET_ALL_FEATURES else None\n",
    "            ),\n",
    "            multi_models=True,\n",
    "            use_static_covariates=USE_STATIC_COVARIATES,\n",
    "            likelihood=likelihood,\n",
    "        ),\n",
    "        \"Random Forest\": RandomForest(\n",
    "            lags=HORIZON_LOOKBACK,\n",
    "            output_chunk_length=HORIZON_FORECAST,\n",
    "            lags_past_covariates=HORIZON_LOOKBACK,\n",
    "            use_static_covariates=USE_STATIC_COVARIATES,\n",
    "        ),\n",
    "        # ############################################\n",
    "        \"DLinear\": DLinearModel(\n",
    "            HORIZON_LOOKBACK,\n",
    "            HORIZON_FORECAST,\n",
    "            kernel_size=10,  # for calculating the moving average to remove trend\n",
    "            use_static_covariates=USE_STATIC_COVARIATES,\n",
    "            use_reversible_instance_norm=USE_REVIN,\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch_wo_dropout(),\n",
    "        ),\n",
    "        \"NLinear\": NLinearModel(\n",
    "            HORIZON_LOOKBACK,\n",
    "            HORIZON_FORECAST,\n",
    "            normalize=not UNCERTAINTY,\n",
    "            use_static_covariates=USE_STATIC_COVARIATES,\n",
    "            use_reversible_instance_norm=USE_REVIN,\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch_wo_dropout(),\n",
    "        ),\n",
    "        \"RNN (LSTM)\": RNNModel(\n",
    "            input_chunk_length=HORIZON_LOOKBACK,\n",
    "            model=\"LSTM\",\n",
    "            # https://unit8co.github.io/darts/userguide/torch_forecasting_models.html#required-target-time-spans-for-training-validation-and-prediction\n",
    "            training_length=HORIZON_LOOKBACK + 1,  # This is an autoregressive model\n",
    "            hidden_dim=64,\n",
    "            n_rnn_layers=3,\n",
    "            # Should not be used with use_reversible_instance_norm=True\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch(),\n",
    "        ),\n",
    "        \"RNN (GRU)\": RNNModel(\n",
    "            # See \"RNN (LSTM)\" above for comments\n",
    "            input_chunk_length=HORIZON_LOOKBACK,\n",
    "            model=\"GRU\",\n",
    "            training_length=HORIZON_LOOKBACK + 1,\n",
    "            hidden_dim=64,\n",
    "            n_rnn_layers=3,\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch(),\n",
    "        ),\n",
    "        \"Block RNN (LSTM)\": BlockRNNModel(\n",
    "            # See \"RNN (LSTM)\" above for comments\n",
    "            input_chunk_length=HORIZON_LOOKBACK,\n",
    "            output_chunk_length=HORIZON_FORECAST,\n",
    "            model=\"LSTM\",\n",
    "            hidden_dim=128,\n",
    "            n_rnn_layers=3,\n",
    "            use_reversible_instance_norm=True,\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch(),\n",
    "        ),\n",
    "        \"Block RNN (GRU)\": BlockRNNModel(\n",
    "            # See \"RNN (LSTM)\" above for comments\n",
    "            input_chunk_length=HORIZON_LOOKBACK,\n",
    "            output_chunk_length=HORIZON_FORECAST,\n",
    "            model=\"GRU\",\n",
    "            hidden_dim=128,\n",
    "            n_rnn_layers=3,\n",
    "            use_reversible_instance_norm=True,\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch(),\n",
    "        ),\n",
    "        \"TCN\": TCNModel(\n",
    "            HORIZON_LOOKBACK,\n",
    "            HORIZON_FORECAST,\n",
    "            num_filters=16,\n",
    "            use_reversible_instance_norm=USE_REVIN,\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch(),\n",
    "        ),\n",
    "        \"Transformer\": TransformerModel(\n",
    "            HORIZON_LOOKBACK,\n",
    "            HORIZON_FORECAST,\n",
    "            d_model=120,\n",
    "            dim_feedforward=512,\n",
    "            num_encoder_layers=4,\n",
    "            num_decoder_layers=4,\n",
    "            nhead=6,\n",
    "            activation=\"gelu\",\n",
    "            use_reversible_instance_norm=USE_REVIN,\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch(),\n",
    "        ),\n",
    "        \"TFT\": TFTModel(\n",
    "            HORIZON_LOOKBACK,\n",
    "            HORIZON_FORECAST,\n",
    "            hidden_size=36,\n",
    "            num_attention_heads=6,\n",
    "            full_attention=True,\n",
    "            add_relative_index=True,  # For the forecast without covariates\n",
    "            loss_fn=None if UNCERTAINTY else torch.nn.MSELoss(),\n",
    "            use_static_covariates=USE_STATIC_COVARIATES,\n",
    "            use_reversible_instance_norm=USE_REVIN,\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch(),\n",
    "        ),\n",
    "        \"N-BEATS\": NBEATSModel(\n",
    "            HORIZON_LOOKBACK,\n",
    "            HORIZON_FORECAST,\n",
    "            layer_widths=512,\n",
    "            num_layers=6,\n",
    "            num_blocks=1,\n",
    "            use_reversible_instance_norm=USE_REVIN,\n",
    "            likelihood=likelihood_model(),\n",
    "            **(common_torch() | dict(batch_size=256)),\n",
    "        ),\n",
    "        \"N-HiTS\": NHiTSModel(\n",
    "            HORIZON_LOOKBACK,\n",
    "            HORIZON_FORECAST,\n",
    "            use_reversible_instance_norm=USE_REVIN,\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch(),\n",
    "        ),\n",
    "        \"TiDE\": TiDEModel(\n",
    "            HORIZON_LOOKBACK,\n",
    "            HORIZON_FORECAST,\n",
    "            num_encoder_layers=2,\n",
    "            num_decoder_layers=2,\n",
    "            use_static_covariates=USE_STATIC_COVARIATES,\n",
    "            use_reversible_instance_norm=USE_REVIN,\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch(),\n",
    "        ),\n",
    "        \"xLSTM-Mixer\": xLSTMMixer(\n",
    "            input_chunk_length=HORIZON_LOOKBACK,\n",
    "            output_chunk_length=HORIZON_FORECAST,\n",
    "            use_reversible_instance_norm=USE_REVIN,\n",
    "            likelihood=likelihood_model(),\n",
    "            **common_torch_wo_dropout(),\n",
    "        ),\n",
    "        # ############################################\n",
    "        # See: https://huggingface.co/autogluon/chronos-bolt-base\n",
    "        \"Chronos-Bolt-Small\": ChronosDartsWrapper(\n",
    "            model_name=\"amazon/chronos-bolt-small\"\n",
    "        ),\n",
    "        \"Chronos-Bolt-Base\": ChronosDartsWrapper(model_name=\"amazon/chronos-bolt-base\"),\n",
    "    }\n",
    "    if UNCERTAINTY:\n",
    "        # As of darts version 0.27.2\n",
    "        SUPPORTS_UNCERTAINTY = {\n",
    "            ARIMA,\n",
    "            VARIMA,\n",
    "            StatsForecastAutoARIMA,\n",
    "            # ExponentialSmoothing,\n",
    "            # StatsforecastAutoETS,\n",
    "            # BATS,\n",
    "            # TBATS,\n",
    "            StatsForecastAutoTheta,\n",
    "            Prophet,\n",
    "            # KalmanForecaster,\n",
    "            LinearRegressionModel,\n",
    "            # LightGBMModel,\n",
    "            # XGBModel,\n",
    "            # CatBoostModel,\n",
    "            GlobalForecastingModel,  # All of them\n",
    "        }\n",
    "        return {\n",
    "            name: model\n",
    "            for name, model in models.items()\n",
    "            if (\n",
    "                any(isinstance(model, klass) for klass in SUPPORTS_UNCERTAINTY)\n",
    "                # RandomForest is a GlobalForecastingModel:\n",
    "                and not isinstance(model, RandomForest)\n",
    "            )\n",
    "        }\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(make_models())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments\n",
    "\n",
    "### Fit models & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cross_validation_fold_index, data_entry in enumerate(\n",
    "    generate_splits(\n",
    "        darts_ts,\n",
    "        horizon_lookback=HORIZON_LOOKBACK,\n",
    "        horizon_forecast=HORIZON_FORECAST,\n",
    "        stride=STRIDE,\n",
    "        fraction_validation=0.1,  # We don't have much data\n",
    "        window_mode=WINDOW_MODE,\n",
    "    )\n",
    "):\n",
    "    train_ts, val_ts, test_ts = data_entry\n",
    "\n",
    "    if only_from_to is not None and cross_validation_fold_index not in range(\n",
    "        *only_from_to\n",
    "    ):\n",
    "        continue\n",
    "\n",
    "    cv_path = OUT_PATH / str(cross_validation_fold_index)\n",
    "\n",
    "    result_data_path = cv_path / \"result_data\"\n",
    "    result_data_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    example_predictions_path = result_data_path / \"example_predictions.pkl\"\n",
    "    if example_predictions_path.exists():\n",
    "        print(f\"Skipping {cross_validation_fold_index} as it already exists\")\n",
    "        continue\n",
    "\n",
    "    models = make_models()\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        # For ARIMA-family models, we get a lot of warnings about convergence issues; but also for other models\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            category=UserWarning,\n",
    "            module=\"statsmodels.+\",\n",
    "            append=True,\n",
    "        )\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            category=UserWarning,\n",
    "            module=\"torch.nn.modules.transformer\",\n",
    "            append=True,\n",
    "        )\n",
    "\n",
    "        with ModelEvaluator(\n",
    "            train_ts=train_ts,\n",
    "            val_ts=val_ts,\n",
    "            test_ts=test_ts,\n",
    "            input_chunk_length=HORIZON_LOOKBACK,\n",
    "            output_chunk_length=HORIZON_FORECAST,\n",
    "            checkpoint_path=cv_path / \"checkpoints\",\n",
    "            num_samples=100 if UNCERTAINTY else 1,\n",
    "            group_name=\"wandb_group_name\",\n",
    "            job_type=f\"fold-{cross_validation_fold_index}\",\n",
    "            # evaluate_first_n_companies=20,\n",
    "            # return_first_n_companies=20,\n",
    "            num_processes_local_models=8,\n",
    "        ) as model_evaluator:\n",
    "            results = list(model_evaluator.eval_in_parallel(models, num_workers=8))\n",
    "\n",
    "            # Note: Errors such as \"ValueError: Model `StatsForecastAutoARIMA` only supports univariate TimeSeries\"\n",
    "            # come from the subprocesses where logging is not disabled. This is just darts being noisy.\n",
    "\n",
    "        print(\n",
    "            f\"{len(results)} done out of {len(models)} models, the remaining {len(models) - len(results)} had errors\"\n",
    "        )\n",
    "\n",
    "        metrics_for_pandas = [\n",
    "            (result.metrics | dict(model=result.name)) for result in results\n",
    "        ]\n",
    "        df = pd.DataFrame(metrics_for_pandas).set_index(\"model\")\n",
    "        df.sort_index(inplace=True)\n",
    "        df = df.melt(var_name=\"metric\", ignore_index=False)\n",
    "        df.to_pickle(result_data_path / \"results.pkl\")\n",
    "\n",
    "        example_predictions: dict[str, list[ForecastingResult]] = dict(\n",
    "            SortedDict({result.name: result.test_forecasts for result in results})\n",
    "        )\n",
    "        with open(example_predictions_path, \"wb\") as f:\n",
    "            pickle.dump(example_predictions, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        example_predictions_slim: dict[str, dict[int, TimeSeries]] = {\n",
    "            result.name: {\n",
    "                fc.meta_data[\"companyid\"]: fc.ts_forecast\n",
    "                for fc in result.test_forecasts\n",
    "            }\n",
    "            for result in results\n",
    "        }\n",
    "        with open(result_data_path / \"example_predictions_slim.pkl\", \"wb\") as f:\n",
    "            pickle.dump(example_predictions_slim, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print(f\"Done with cross-validation fold #{cross_validation_fold_index}\")\n",
    "        print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from darts.explainability import TFTExplainer\n",
    "\n",
    "from proprietary_data import companyid_to_name\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_name = companyid_to_name(subset=False, min_length=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainability_path = (\n",
    "    Path(\"forecast_baselines\")\n",
    "    / \"statics_True-revin_True-stride1_lb12-expanding-uq_True\"\n",
    "    / \"0\"\n",
    ")\n",
    "model = TFTModel.load(str(explainability_path / \"checkpoints\" / \"TFT.ckpt\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts, val_ts, test_ts = next(\n",
    "    iter(\n",
    "        generate_splits(\n",
    "            darts_ts, horizon_lookback=12, horizon_forecast=4, window_mode=\"expanding\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_index = 520\n",
    "(\n",
    "    id_to_name[train_ts.meta_data[company_index][\"companyid\"]],\n",
    "    test_ts.targets[company_index].start_time(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = TFTExplainer(\n",
    "    model,\n",
    "    background_series=train_ts.targets[company_index],\n",
    "    background_past_covariates=train_ts.covariates[company_index],\n",
    ")\n",
    "explainability_result = explainer.explain(\n",
    "    # foreground_series=train_ts.targets[company_index],\n",
    "    # foreground_past_covariates=train_ts.covariates[company_index],\n",
    ")\n",
    "explainability_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.plot_variable_selection(explainability_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = explainability_result.get_attention().mean(axis=1)\n",
    "\n",
    "train_ice_transformed = train_ts.targets[company_index]\n",
    "\n",
    "time_intersection = train_ice_transformed.time_index.intersection(attention.time_index)\n",
    "\n",
    "train_ice_transformed[time_intersection].plot()\n",
    "attention.plot(label=\"mean_attention\", max_nr_components=12)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect for all splits\n",
    "\n",
    "results = {\"encoder\": [], \"static\": []}\n",
    "\n",
    "for split_id, split_data in enumerate(\n",
    "    track(\n",
    "        generate_splits(\n",
    "            darts_ts, horizon_lookback=12, horizon_forecast=4, window_mode=\"expanding\"\n",
    "        ),\n",
    "        total=40,\n",
    "    )\n",
    "):\n",
    "    train_ts, val_ts, test_ts = split_data\n",
    "\n",
    "    model = TFTModel.load(\n",
    "        str(explainability_path.parent / str(split_id) / \"checkpoints\" / \"TFT.ckpt\")\n",
    "    )\n",
    "    explainer = TFTExplainer(\n",
    "        model,\n",
    "        background_series=train_ts.targets[company_index],\n",
    "        background_past_covariates=train_ts.covariates[company_index],\n",
    "    )\n",
    "    explainability_result = explainer.explain()\n",
    "\n",
    "    encoder_imp = explainability_result.get_encoder_importance()\n",
    "    static_imp = explainability_result.get_static_covariates_importance()\n",
    "\n",
    "    results[\"encoder\"].append(encoder_imp)\n",
    "    results[\"static\"].append(static_imp)\n",
    "\n",
    "encoder_imp_sum = sum(results[\"encoder\"]) / len(results[\"encoder\"])\n",
    "static_imp_sum = sum(results[\"static\"]) / len(results[\"static\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_imp = explainability_result.get_encoder_importance()\n",
    "# static_imp = explainability_result.get_static_covariates_importance()\n",
    "\n",
    "encoder_imp = encoder_imp_sum.reindex(encoder_imp_sum.sum().sort_values().index, axis=1)\n",
    "static_imp = static_imp_sum.reindex(static_imp_sum.sum().sort_values().index, axis=1)\n",
    "\n",
    "# Make it a bit more readable\n",
    "encoder_imp = encoder_imp[encoder_imp.columns[encoder_imp.max() > 3]]\n",
    "static_imp = static_imp[static_imp.columns[static_imp.max() > 10]]\n",
    "\n",
    "encoder_imp.columns = (\n",
    "    encoder_imp.columns.str.replace(\"_pastcov\", \" (Past Covariate)\")\n",
    "    .str.replace(\"_target\", \" (Past Target)\")\n",
    "    .str.replace(\n",
    "        \"add_relative_index_futcov\", \"Synthetic Relative Index (Future Covariate)\"\n",
    "    )\n",
    "    .str.replace(\"Short Term Investments\", \"Short Term Inv.\")\n",
    ")\n",
    "\n",
    "static_imp.columns = (\n",
    "    static_imp.columns.str.replace(\"_statcov\", \"\")\n",
    "    .str.replace(\"_\", \" \")\n",
    "    .str.replace(\"GICS sector \", \"GICS sector: \")\n",
    ")\n",
    "\n",
    "uses_static_covariates = not static_imp.empty\n",
    "\n",
    "# plot the encoder and decoder weights\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2 if uses_static_covariates else 1,\n",
    "    sharex=True,\n",
    "    squeeze=False,\n",
    "    subplot_kw=dict(aspect=0.45),\n",
    ")\n",
    "axes = axes.flatten()\n",
    "explainer._plot_cov_selection(encoder_imp, title=\"\", ax=axes[0])\n",
    "# axes[0].xaxis.set_ticks_position(\"top\")\n",
    "axes[0].xaxis.set_label_position(\"top\")\n",
    "fontsize = 10  # Reset the font size\n",
    "axes[0].set_xlabel(axes[0].get_xlabel(), fontsize=fontsize)\n",
    "axes[0].set_ylabel(\"Covariates\", fontsize=fontsize)\n",
    "\n",
    "if uses_static_covariates:\n",
    "    explainer._plot_cov_selection(\n",
    "        static_imp,\n",
    "        title=\"\",\n",
    "        ax=axes[1],\n",
    "    )\n",
    "    axes[1].xaxis.set_label_position(\"top\")\n",
    "    axes[1].set_xlabel(\"\")\n",
    "    axes[1].set_ylabel(\"Static Variables\", fontsize=fontsize)\n",
    "\n",
    "\n",
    "# move them toghether\n",
    "plt.subplots_adjust(hspace=-0.4)\n",
    "fig.align_ylabels(axes)\n",
    "sns.despine(top=True, bottom=True)\n",
    "\n",
    "path = explainability_path / \"tft_explainability.pdf\"\n",
    "plt.savefig(path, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "str(path.absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
