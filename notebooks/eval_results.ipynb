{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Baselines - Evaluating the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from rich.progress import track\n",
    "from rich.console import Console\n",
    "from darts import TimeSeries\n",
    "from pyro.ops.stats import crps_empirical\n",
    "import torch\n",
    "from torchmetrics import functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "from proprietary_data import (\n",
    "    companyid_to_name,\n",
    "    ALL_FEATURE_NAMES,\n",
    "    KEY_FEATURE_NAMES,\n",
    "    CompanyFundamentalsKind,\n",
    "    get_data_transform,\n",
    "    get_adjusted_inverse_transform,\n",
    ")\n",
    "from proprietary_data.darts import (\n",
    "    load_company_fundamentals_as_darts_time_series,\n",
    "    load_company_fundamental_human_analysts_as_darts_time_series,\n",
    ")\n",
    "from forecasting_cfs.eval_model import ForecastingResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps_empirical_numpy(pred: np.ndarray, truth: np.ndarray) -> np.ndarray:\n",
    "    return crps_empirical(torch.tensor(pred), torch.tensor(truth)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = (\n",
    "    Path(\"forecast_baselines\")\n",
    "    / \"statics_True-revin_True-stride1_lb12-expanding-uq_True\"\n",
    ")\n",
    "assert OUT_PATH.exists(), f\"Path {OUT_PATH.absolute()} does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette: str = \"muted\"\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_FOR_ALL_MODELS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDE = {\"ARIMA(4,1,4)\", \"VARIMA(4,0,4)\", \"VARIMA(4,1,4)\"}  # Too unstable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a single fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_OUT_PATH = OUT_PATH / \"0\" / \"result_data\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and prepare it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_fold: pd.DataFrame = pd.read_pickle(SINGLE_OUT_PATH / \"results.pkl\")\n",
    "df_single_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNCEARTAINTY = df_single_fold.empty\n",
    "UNCEARTAINTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_fold.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_fold[\"metric\"][\n",
    "    df_single_fold[\"metric\"].str.contains(\"(avg)\", regex=False)\n",
    "].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SINGLE_OUT_PATH / \"example_predictions.pkl\", \"rb\") as f:\n",
    "    example_predictions: Dict[str, List[ForecastingResult]] = pickle.load(f)\n",
    "\n",
    "one_example_prediction = next(iter(example_predictions.values()))\n",
    "len(example_predictions), len(one_example_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = one_example_prediction[0].ts_forecast.n_samples if UNCEARTAINTY else None\n",
    "N_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON_LOOKBACK = one_example_prediction[0].ts_past.n_timesteps\n",
    "HORIZON_LOOKBACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON_FORECAST = one_example_prediction[0].ts_forecast.n_timesteps\n",
    "HORIZON_FORECAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = one_example_prediction[0].ts_ground_truth.n_components\n",
    "NUM_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match NUM_FEATURES:\n",
    "    case 19:\n",
    "        FEATURE_NAMES = ALL_FEATURE_NAMES\n",
    "    case 5:\n",
    "        FEATURE_NAMES = KEY_FEATURE_NAMES\n",
    "    case _:\n",
    "        raise ValueError(f\"Unexpected number of features: {NUM_FEATURES}\")\n",
    "\n",
    "FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_id_to_name = companyid_to_name(subset=False, min_length=\"max\")\n",
    "inverse_transform = get_adjusted_inverse_transform(FEATURE_NAMES)\n",
    "inverse_transform_human_analyst = get_adjusted_inverse_transform(\n",
    "    [\"Revenue F12M Analyst Estimate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_avg(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_avg = df[df[\"metric\"].str.endswith(\"(avg)\")]\n",
    "    # assert df_avg.index.is_unique\n",
    "    return df_avg.astype({\"value\": float})\n",
    "\n",
    "\n",
    "melt_avg(df_single_fold).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_avg_for_human(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_avg = df[df[\"metric\"].str.endswith(\"(avg as human eval)\")]\n",
    "    # assert df_avg.index.is_unique\n",
    "    return df_avg.astype({\"value\": float})\n",
    "\n",
    "\n",
    "melt_avg(df_single_fold).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_lookahead(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_lh_molten = df[df[\"metric\"].str.endswith(\"(avg per lookahead)\")]\n",
    "    df_lh_molten = df_lh_molten.explode(\"value\", ignore_index=False)\n",
    "    df_lh_molten[\"look-ahead\"] = (np.arange(len(df_lh_molten)) % HORIZON_FORECAST) + 1\n",
    "    # assert df_lh_molten.index.is_unique\n",
    "    return df_lh_molten.astype({\"value\": float})\n",
    "\n",
    "\n",
    "melt_lookahead(df_single_fold).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_feat_molten = df[df[\"metric\"].str.endswith(\"(avg per feature)\")]\n",
    "    df_feat_molten = df_feat_molten.explode(\"value\", ignore_index=False)\n",
    "    df_feat_molten[\"feature\"] = np.arange(len(df_feat_molten)) % NUM_FEATURES\n",
    "    # assert df_feat_molten.index.is_unique\n",
    "    return df_feat_molten.astype({\"value\": float})\n",
    "\n",
    "\n",
    "melt_feature(df_single_fold).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show aggregated prediction errors and error over look-ahead horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(\n",
    "    df: pd.DataFrame,\n",
    "    save_dir: Path,\n",
    "    postfix: str = \"\",\n",
    "    show_metrics: List[str] = [\"MAE\", \"MAPE\", \"MSE\", \"R2\", \"RMSE\", \"RSE\", \"SMAPE\"],\n",
    "    # show_metrics: List[str] = [\"nCRPS\"],\n",
    "    exclude: set[str] = EXCLUDE,\n",
    ") -> None:\n",
    "    df_single = melt_avg(df)\n",
    "    df_single = df_single[\n",
    "        df_single[\"metric\"].str.split(\" \", n=2, expand=True)[0].isin(show_metrics)\n",
    "    ]\n",
    "    df_single.reset_index(inplace=True)\n",
    "    df_single = df_single[~df_single[\"model\"].isin(exclude)]\n",
    "    df_single.sort_values(by=[\"model\"], inplace=True)\n",
    "\n",
    "    df_lh_molten = melt_lookahead(df)\n",
    "    df_single.sort_values(by=[\"model\"], inplace=True)\n",
    "    df_lh_molten = df_lh_molten[\n",
    "        df_lh_molten[\"metric\"].str.split(\" \", n=2, expand=True)[0].isin(show_metrics)\n",
    "    ]\n",
    "    # make it categorical:\n",
    "    df_lh_molten[\"look-ahead\"] = df_lh_molten[\"look-ahead\"].astype(\"str\")\n",
    "    df_lh_molten.reset_index(inplace=True)\n",
    "    df_lh_molten = df_lh_molten[~df_lh_molten[\"model\"].isin(exclude)]\n",
    "    df_lh_molten.sort_values(by=[\"model\", \"look-ahead\"], inplace=True)\n",
    "\n",
    "    save_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    plot: sns.FacetGrid = sns.catplot(\n",
    "        data=df_single.reset_index(),\n",
    "        x=\"model\",\n",
    "        y=\"value\",\n",
    "        hue=\"model\",\n",
    "        col=\"metric\",\n",
    "        col_wrap=1,\n",
    "        kind=\"bar\",\n",
    "        palette=palette,\n",
    "        sharex=True,\n",
    "        sharey=False,\n",
    "        legend=False,\n",
    "        aspect=4,\n",
    "    )\n",
    "    plot.set_xticklabels(rotation=45, horizontalalignment=\"right\")\n",
    "    # plt.subplots_adjust(hspace=0.25)\n",
    "    plt.savefig(save_dir / f\"comparison_avg{postfix}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plot: sns.FacetGrid = sns.relplot(\n",
    "        data=df_lh_molten.dropna(),\n",
    "        x=\"look-ahead\",\n",
    "        y=\"value\",\n",
    "        hue=\"model\",\n",
    "        style=\"model\",\n",
    "        col=\"metric\",\n",
    "        kind=\"line\",\n",
    "        palette=palette,\n",
    "        facet_kws={\"sharey\": False},\n",
    "    )\n",
    "    plt.savefig(save_dir / f\"comparison_lookahead{postfix}.pdf\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if not UNCEARTAINTY:\n",
    "    plot_comparison(df_single_fold, save_dir=SINGLE_OUT_PATH.parent / \"plots\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show error per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_per_feature(\n",
    "    df: pd.DataFrame,\n",
    "    save_dir: Path,\n",
    "    selected_metric: str = \"SMAPE (avg per feature)\",\n",
    "    title: str = \"SMAPE per model and feature\",\n",
    "):\n",
    "    df_feat_molten_selected = melt_feature(df[df[\"metric\"] == selected_metric])\n",
    "    heatmap_data = (\n",
    "        df_feat_molten_selected.reset_index()\n",
    "        .pivot(columns=\"feature\", index=\"model\", values=\"value\")\n",
    "        .sort_values(by=[\"feature\"], axis=\"columns\")\n",
    "    )\n",
    "    heatmap_data.rename(columns=FEATURE_NAMES.__getitem__, inplace=True)\n",
    "\n",
    "    df_feat_molten_selected[\"feature\"] = df_feat_molten_selected[\"feature\"].apply(\n",
    "        FEATURE_NAMES.__getitem__\n",
    "    )\n",
    "\n",
    "    with sns.axes_style(\"white\"):\n",
    "        g = sns.JointGrid(\n",
    "            data=df_feat_molten_selected,\n",
    "            x=\"feature\",\n",
    "            y=\"model\",\n",
    "            hue=\"value\",\n",
    "            marginal_ticks=True,\n",
    "            # ratio=10,\n",
    "        )\n",
    "\n",
    "        # Create an inset legend for the histogram colorbar\n",
    "        cax = g.figure.add_axes([0.9, 0.85, 0.015, 0.12])\n",
    "\n",
    "        # Add the joint and marginal histogram plots\n",
    "        h = sns.heatmap(\n",
    "            data=heatmap_data,\n",
    "            ax=g.ax_joint,\n",
    "            cbar_ax=cax,\n",
    "            annot=True,\n",
    "            fmt=\".3f\",\n",
    "            annot_kws=dict(fontsize=\"xx-small\"),\n",
    "        )\n",
    "        cmap = cax.collections[1].get_cmap()\n",
    "        cmap_norm = cax.collections[1].norm\n",
    "        h.set_xticklabels(h.get_xticklabels(), rotation=45, horizontalalignment=\"right\")\n",
    "        # b = sns.barplot(\n",
    "        #     data=df_feat_molten_selected,\n",
    "        #     ax=g.ax_marg_x,\n",
    "        #     x=\"feature\",\n",
    "        #     y=\"value\",\n",
    "        #     orient=\"v\",\n",
    "        #     color=\"skyblue\",\n",
    "        # )\n",
    "        # sns.barplot(\n",
    "        #     data=df_feat_molten_selected.reset_index(),\n",
    "        #     ax=g.ax_marg_y,\n",
    "        #     y=\"model\",\n",
    "        #     x=\"value\",\n",
    "        #     orient=\"h\",\n",
    "        #     color=\"skyblue\",\n",
    "        # )\n",
    "        bar_data = (\n",
    "            df_feat_molten_selected.groupby([\"feature\"])[\"value\"].mean().to_numpy()\n",
    "        )\n",
    "        g.ax_marg_x.bar(\n",
    "            g.ax_joint.get_xticks(),\n",
    "            bar_data,\n",
    "            align=\"center\",\n",
    "            color=cmap(cmap_norm(bar_data)),\n",
    "        )\n",
    "        barh_data = (\n",
    "            df_feat_molten_selected.groupby([\"model\"])[\"value\"].mean().to_numpy()\n",
    "        )\n",
    "        g.ax_marg_y.barh(\n",
    "            g.ax_joint.get_yticks(),\n",
    "            barh_data,\n",
    "            align=\"center\",\n",
    "            color=cmap(cmap_norm(barh_data)),\n",
    "        )\n",
    "\n",
    "        plt.subplots_adjust(top=0.95)\n",
    "        plt.suptitle(title)\n",
    "\n",
    "    plt.savefig(save_dir / \"error_per_feature.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if not UNCEARTAINTY:\n",
    "    plot_per_feature(df_single_fold, save_dir=SINGLE_OUT_PATH.parent / Path(\"plots\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_result_to_df(\n",
    "    results: list[ForecastingResult], first_n_companies: int = 15\n",
    "):\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"companyid\": int(result.meta_data[\"companyid\"]),\n",
    "                \"companyname\": company_id_to_name[int(result.meta_data[\"companyid\"])],\n",
    "                # \"GICS_sector\": int(result.meta_data[\"GICS_sector\"]),\n",
    "                # \"GICS_industry_group\": int(result.meta_data[\"GICS_industry_group\"]),\n",
    "                \"metadata\": repr(result.meta_data),\n",
    "                \"time\": time,\n",
    "                \"label\": mode,\n",
    "                \"variable\": component_name,\n",
    "                \"value_transformed\": value_transformed,\n",
    "                \"value\": value,\n",
    "            }\n",
    "            for result in results[:first_n_companies]\n",
    "            if result.ts_forecast is not None\n",
    "            for ts, mode in zip(\n",
    "                (\n",
    "                    result.ts_past,\n",
    "                    # This connects the past and future/predicted time series with a line\n",
    "                    result.ts_ground_truth.prepend(result.ts_past[-1:]),\n",
    "                    result.ts_forecast.prepend_values(\n",
    "                        result.ts_past[-1:].values()[..., None][\n",
    "                            ..., [0] * result.ts_forecast.n_samples\n",
    "                        ]\n",
    "                    ),\n",
    "                ),\n",
    "                [\"past\", \"future\", \"forecast\"],\n",
    "            )\n",
    "            for row_transformed, row, component_name in zip(\n",
    "                ts.all_values().T,\n",
    "                inverse_transform(ts.all_values()).T,\n",
    "                ts.components,\n",
    "            )\n",
    "            for time, value_transformed, value in zip(\n",
    "                ts.time_index, row_transformed, row\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    df = df.set_index(\"companyid\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# prediction_result_to_df(example_predictions[\"RNN (GRU)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_first = True\n",
    "# for model, results in track(\n",
    "#     list(example_predictions.items()), description=\"Plotting per model\"\n",
    "# ):\n",
    "#     data = prediction_result_to_df(results)\n",
    "#     for variable in (\"value\", \"value_transformed\"):\n",
    "#         sns.relplot(\n",
    "#             data=data,\n",
    "#             col=\"variable\",\n",
    "#             hue=\"companyname\",\n",
    "#             col_wrap=4,\n",
    "#             x=\"time\",\n",
    "#             y=variable,\n",
    "#             style=\"label\",\n",
    "#             kind=\"line\",\n",
    "#             aspect=1.5,\n",
    "#             facet_kws={\"sharey\": False, \"sharex\": True},\n",
    "#         )\n",
    "#         directory = SINGLE_OUT_PATH.parent / \"plots\" / \"concrete_examples\"\n",
    "#         directory.mkdir(exist_ok=True, parents=True)\n",
    "#         plt.savefig(directory / f\"{model}_{variable}.pdf\")\n",
    "#         if is_first:\n",
    "#             plt.show()\n",
    "#             is_first = False\n",
    "\n",
    "#         plt.close()\n",
    "\n",
    "#     if not PLOT_FOR_ALL_MODELS:\n",
    "#         print(\"Limiting to the first model to be faster\")\n",
    "#         break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview over multiple folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the exact same setup as when training the models\n",
    "\n",
    "darts_ts = load_company_fundamentals_as_darts_time_series(\n",
    "    kind=CompanyFundamentalsKind.Normalized,\n",
    "    subset=False,\n",
    "    target_columns=FEATURE_NAMES,\n",
    "    covariate_columns=[item for item in ALL_FEATURE_NAMES if item not in FEATURE_NAMES],\n",
    "    # only use complete sequences for simplicity when comparing to other models:\n",
    "    min_length=\"max\",\n",
    ")\n",
    "\n",
    "darts_ts_human_analyst = load_company_fundamental_human_analysts_as_darts_time_series(\n",
    "    kind=CompanyFundamentalsKind.Normalized,\n",
    "    subset=False,\n",
    "    # only use complete sequences for simplicity when comparing to other models:\n",
    "    min_length=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of different timestamps with each a mapping of: model -> companyid -> timeseries\n",
    "forecasts: list[dict[str, dict[int, TimeSeries]]] = []\n",
    "\n",
    "for split_directory in track(\n",
    "    list(\n",
    "        sorted(\n",
    "            filter(\n",
    "                lambda path: path.is_dir() and not path.name == \"plots\",\n",
    "                OUT_PATH.iterdir(),\n",
    "            ),\n",
    "            key=lambda path: int(path.name),\n",
    "        )\n",
    "    ),\n",
    "    description=\"Loading predictions\",\n",
    "):\n",
    "    with open(split_directory / \"result_data\" / \"example_predictions.pkl\", \"rb\") as f:\n",
    "        forecasts.append(pickle.load(f))\n",
    "\n",
    "\n",
    "len(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ORDER_MODELS = list(sorted(forecasts[0]))\n",
    "    for model in EXCLUDE:\n",
    "        if model in ORDER_MODELS:\n",
    "            ORDER_MODELS.remove(model)\n",
    "\n",
    "    ORDER_COMPANIES = list(\n",
    "        sorted(\n",
    "            set(\n",
    "                forecast_result.meta_data[\"companyid\"]\n",
    "                for forecast_result in forecasts[0][ORDER_MODELS[0]]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "except NameError:\n",
    "    raise RuntimeError(\"the forecasts_slim is not trustworthy\")\n",
    "\n",
    "    ORDER_MODELS = list(sorted(forecasts_slim[0]))\n",
    "    for model in EXCLUDE:\n",
    "        if model in ORDER_MODELS:\n",
    "            ORDER_MODELS.remove(model)\n",
    "\n",
    "    ORDER_COMPANIES = list(sorted(set(forecasts_slim[0][ORDER_MODELS[0]].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example time series:\n",
    "# forecasts[0][ORDER_MODELS[0]][18671]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_per_window = {\n",
    "    forecast_id: list(sorted(forecast.keys()))\n",
    "    for forecast_id, forecast in enumerate(forecasts)\n",
    "}\n",
    "df_models_per_window = (\n",
    "    pd.DataFrame(models_per_window.items(), columns=[\"window\", \"models\"])\n",
    "    .explode(\"models\")\n",
    "    .groupby(\"models\")\n",
    "    .count()\n",
    "    .rename(columns={\"window\": \"present in # windows\"})\n",
    ")\n",
    "df_models_per_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index_to_start_time = {\n",
    "    split_index: (\n",
    "        forecast[ORDER_MODELS[0]][0]\n",
    "        .ts_forecast.start_time()\n",
    "        .strftime(\"%Y %m\")\n",
    "        .replace(\" 01\", \" Q1\")\n",
    "        .replace(\" 04\", \" Q2\")\n",
    "        .replace(\" 07\", \" Q3\")\n",
    "        .replace(\" 10\", \" Q4\")\n",
    "    )\n",
    "    for split_index, forecast in enumerate(forecasts)\n",
    "}\n",
    "split_index_to_start_time  # Also defined manually down for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_per_company = {\n",
    "    company_id: darts_ts.where_meta_data_matches(\n",
    "        key=\"companyid\", value=company_id\n",
    "    ).targets[0]\n",
    "    for company_id in company_id_to_name\n",
    "}\n",
    "len(ground_truth_per_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huamn_analyst_per_company = {\n",
    "    company_id: darts_ts_human_analyst.where_meta_data_matches(\n",
    "        key=\"companyid\", value=company_id\n",
    "    ).targets[0]\n",
    "    for company_id in company_id_to_name\n",
    "}\n",
    "len(huamn_analyst_per_company) == len(ground_truth_per_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ground_truth_data_processed = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"split\": \"true\",\n",
    "            \"model\": None,\n",
    "            \"company_id\": company_id,\n",
    "            \"time\": time,\n",
    "            \"label\": \"true\",\n",
    "            \"variable\": component_name,\n",
    "            \"EUR transformed\": value_transformed,\n",
    "            # \"EUR\": value,\n",
    "        }\n",
    "        for company_id, ground_truth in ground_truth_per_company.items()\n",
    "        for row_transformed, row, component_name in zip(\n",
    "            ground_truth.all_values().squeeze(-1).T,\n",
    "            ground_truth.all_values().squeeze(-1).T,\n",
    "            # inverse_transform(ground_truth.all_values().squeeze(-1)).T,  # TODO\n",
    "            ground_truth.components,\n",
    "        )\n",
    "        for time, value_transformed, value in zip(\n",
    "            ground_truth.time_index, row_transformed, row\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "_ground_truth_data_processed.to_parquet(\n",
    "    OUT_PATH / \"ground_truth_data_processed.parquet\"\n",
    ")\n",
    "_ground_truth_data_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ground_truth_data_processed = pd.read_parquet(\n",
    "    OUT_PATH / \"ground_truth_data_processed.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_human_analyst_data_processed = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"split\": \"human analyst\",\n",
    "            \"model\": \"human analyst\",\n",
    "            \"company_id\": company_id,\n",
    "            \"time\": time,\n",
    "            \"label\": \"human analyst\",\n",
    "            \"variable\": component_name,\n",
    "            \"EUR transformed\": value_transformed,\n",
    "            \"EUR\": value,\n",
    "        }\n",
    "        for company_id, ground_truth in huamn_analyst_per_company.items()\n",
    "        for row_transformed, row, component_name in zip(\n",
    "            ground_truth.all_values().squeeze(-1).T,\n",
    "            ground_truth.all_values().squeeze(-1).T,\n",
    "            # inverse_transform_human_analyst(ground_truth.all_values().squeeze(-1)).T,  # TODO\n",
    "            ground_truth.components,\n",
    "        )\n",
    "        for time, value_transformed, value in zip(\n",
    "            ground_truth.time_index, row_transformed, row\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "_human_analyst_data_processed.to_parquet(\n",
    "    OUT_PATH / \"human_analyst_data_processed.parquet\"\n",
    ")\n",
    "_human_analyst_data_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_human_analyst_data_processed = pd.read_parquet(\n",
    "    OUT_PATH / \"human_analyst_data_processed.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = forecasts[0][ORDER_MODELS[0]][2].ts_forecast\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = get_data_transform(subset=False, min_length=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_back_to_original(\n",
    "    time_series: TimeSeries, company_id: int, normalize_date=None\n",
    ") -> TimeSeries:\n",
    "    as_array = np.zeros(\n",
    "        (\n",
    "            time_series.n_timesteps,\n",
    "            len(data_transform._feature_names),\n",
    "            time_series.n_samples,\n",
    "        )\n",
    "    )\n",
    "    indices = [\n",
    "        data_transform._feature_names.index(feat) for feat in time_series.components\n",
    "    ]\n",
    "    as_array[:, indices, :] = time_series.all_values()\n",
    "    inverted = data_transform.standardizer.inverse_transform(\n",
    "        rearrange(as_array, \"time component sample -> (time sample) component\")\n",
    "    )\n",
    "    inverted = rearrange(\n",
    "        # Restrict to the components of the time series\n",
    "        inverted[:, indices],\n",
    "        \"(time sample) component -> time component sample\",\n",
    "        time=time_series.n_timesteps,\n",
    "    )\n",
    "\n",
    "    normalizer = data_transform._source_data[\n",
    "        data_transform._source_data[\"companyid\"] == company_id\n",
    "    ]\n",
    "    if normalize_date is None:\n",
    "        normalizer = normalizer[normalizer[\"aca_quarter\"] < ts.time_index.min()]\n",
    "        normalizer = normalizer[\n",
    "            normalizer[\"aca_quarter\"] == normalizer[\"aca_quarter\"].max()\n",
    "        ]\n",
    "    else:\n",
    "        normalizer = normalizer[normalizer[\"aca_quarter\"] == normalize_date]\n",
    "    assert len(normalizer) == 1, normalizer\n",
    "\n",
    "    for col, col_normalizer in data_transform._normalizer_mapping.items():\n",
    "        if col in time_series.components:\n",
    "            index = time_series.components.get_loc(col)\n",
    "            inverted[:, index, :] = inverted[:, index, :] * (\n",
    "                normalizer[col_normalizer].item() + data_transform.eps\n",
    "            )\n",
    "\n",
    "    return inverted\n",
    "\n",
    "\n",
    "transform_back_to_original(ts, company_id=18527).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_for_company_results(\n",
    "    forecasts, model: str, include_companies: Optional[List[int]] = None\n",
    ") -> pd.DataFrame:\n",
    "    include_company_indices = [ORDER_COMPANIES.index(c) for c in include_companies]\n",
    "    df_specific = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"split\": f\"forecast #{split}\",\n",
    "                \"model\": model,\n",
    "                \"company_id\": ORDER_COMPANIES[company_index],\n",
    "                \"time\": time,\n",
    "                \"label\": label,\n",
    "                \"variable\": component_name,\n",
    "                \"EUR transformed\": value_transformed,\n",
    "                \"EUR\": value,\n",
    "                \"sample_idx\": sample_idx,\n",
    "            }\n",
    "            for split, ts_in_split in enumerate(\n",
    "                track(\n",
    "                    forecasts,\n",
    "                    description=f\"Computing data for model '{model}' for various splits\",\n",
    "                    disable=True,\n",
    "                )\n",
    "            )\n",
    "            for company_index, result in enumerate(ts_in_split[model])\n",
    "            if result is not None\n",
    "            and (include_companies is None or company_index in include_company_indices)\n",
    "            for ts_unconnected in [result.ts_forecast]\n",
    "            # for ground_truth in [ground_truth_per_company[company_id]]\n",
    "            for ts in [\n",
    "                # # This is a hacky way to connect the past and future/predicted time series with a line\n",
    "                ts_unconnected.prepend_values(\n",
    "                    # values has shape (time, component, sample),\n",
    "                    result.ts_past.all_values()[-1:, :, [0] * ts_unconnected.n_samples]\n",
    "                    # ground_truth[\n",
    "                    #     ground_truth.get_index_at_point(\n",
    "                    #         ground_truth._get_last_timestamp_before(\n",
    "                    #             ts_unconnected.start_time()\n",
    "                    #         )\n",
    "                    #     )\n",
    "                    #     - 1 : ground_truth.get_index_at_point(\n",
    "                    #         ground_truth._get_last_timestamp_before(\n",
    "                    #             ts_unconnected.start_time()\n",
    "                    #         )\n",
    "                    #     )\n",
    "                    # ].values()[..., None][..., [0] * ts_unconnected.n_samples]\n",
    "                )\n",
    "            ]\n",
    "            for ts, label in [\n",
    "                (ts, \"forecast\"),\n",
    "                # ts_ground_truth and ts_past only contain the testing split data, so not the full data!\n",
    "                *(\n",
    "                    # Add all the data from the last split, since it contains all of it\n",
    "                    [(result.ts_past, \"true\"), (result.ts_ground_truth, \"true\")]\n",
    "                    if split == 0\n",
    "                    else [(result.ts_ground_truth, \"true\")]\n",
    "                ),\n",
    "            ]\n",
    "            for sample_idx in range(ts.n_samples)  # Inefficient order, but works\n",
    "            for row_transformed, row, component_name in zip(\n",
    "                ts.values(sample=sample_idx).T,\n",
    "                # ts.all_values()[..., sample_idx].T,\n",
    "                transform_back_to_original(\n",
    "                    ts, company_id=ORDER_COMPANIES[company_index]\n",
    "                )[:, :, sample_idx].T,\n",
    "                ts.components,\n",
    "            )\n",
    "            for time, value_transformed, value in zip(\n",
    "                ts.time_index,\n",
    "                row_transformed,\n",
    "                row,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return pd.concat(\n",
    "        [\n",
    "            df_specific\n",
    "        ],  # _ground_truth_data_processed, _human_analyst_data_processed],  # TODO exclude irrelevant companies here\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# make_df_for_company_results(\n",
    "#     forecasts, \"Prophet\", include_companies=list(company_id_to_name.keys())[:1]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the market evaluation, we need:\n",
    "- company_id\n",
    "- last_known_date\n",
    "- feature\n",
    "- forecasting_step (the zeroth quarter is the ground truth)\n",
    "- value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_for_export(forecasts, model: str) -> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"company_id\": ORDER_COMPANIES[company_index],\n",
    "                \"last_known_time\": last_known_time,\n",
    "                \"step\": step,\n",
    "                \"variable\": component_name,\n",
    "                \"EUR transformed\": value_transformed,\n",
    "                \"EUR\": value,\n",
    "                \"EUR transformed (std)\": std_transformed,\n",
    "                \"EUR (std)\": std,\n",
    "            }\n",
    "            for split, ts_in_split in enumerate(\n",
    "                track(\n",
    "                    forecasts  # disable=True,\n",
    "                )\n",
    "            )\n",
    "            # if split in [34, 35, 36, 37, 38, 39, 40]  # TODO\n",
    "            for company_index, result in enumerate(ts_in_split[model])\n",
    "            if result is not None  # and company_index in [0, 1]  # TODO\n",
    "            for ts_mean_forecast in [result.ts_forecast.mean()]\n",
    "            for ts_std_forecast in [result.ts_forecast.std()]\n",
    "            for normalize_date in [result.ts_past.end_time()]\n",
    "            for fc_transformed, fc, fc_transformed_std, fc_std, past_transformed, past, gt_transformed, gt, component_name in zip(\n",
    "                ts_mean_forecast.values().T,\n",
    "                transform_back_to_original(\n",
    "                    ts_mean_forecast,\n",
    "                    company_id=ORDER_COMPANIES[company_index],\n",
    "                    normalize_date=normalize_date,\n",
    "                )[:, :, 0].T,\n",
    "                ts_std_forecast.values().T,\n",
    "                transform_back_to_original(\n",
    "                    ts_std_forecast,\n",
    "                    company_id=ORDER_COMPANIES[company_index],\n",
    "                    normalize_date=normalize_date,\n",
    "                )[:, :, 0].T,\n",
    "                result.ts_past.values()[-1:, :].T,\n",
    "                transform_back_to_original(\n",
    "                    result.ts_past[-1:],\n",
    "                    company_id=ORDER_COMPANIES[company_index],\n",
    "                    normalize_date=normalize_date,\n",
    "                )[:, :, 0].T,\n",
    "                result.ts_ground_truth.values()[:, :].T,\n",
    "                transform_back_to_original(\n",
    "                    result.ts_ground_truth,\n",
    "                    company_id=ORDER_COMPANIES[company_index],\n",
    "                    normalize_date=normalize_date,\n",
    "                )[:, :, 0].T,\n",
    "                ts.components,\n",
    "            )\n",
    "            for step, value_transformed, value, std_transformed, std, last_known_time in [\n",
    "                (0, past_transformed.item(), past.item(), None, None, normalize_date),\n",
    "                *[\n",
    "                    (\n",
    "                        step + 1,\n",
    "                        fc_transformed[step].item(),\n",
    "                        fc[step].item(),\n",
    "                        fc_transformed_std[step].item(),\n",
    "                        fc_std[step].item(),\n",
    "                        normalize_date,\n",
    "                    )\n",
    "                    for step in range(result.ts_forecast.n_timesteps)\n",
    "                ],\n",
    "                *(\n",
    "                    []\n",
    "                    if split < len(forecasts) - 1\n",
    "                    else [\n",
    "                        (\n",
    "                            0,\n",
    "                            gt_transformed[step].item(),\n",
    "                            gt[step].item(),\n",
    "                            None,\n",
    "                            None,\n",
    "                            result.ts_ground_truth.time_index[step],\n",
    "                        )\n",
    "                        for step in range(result.ts_ground_truth.n_timesteps)\n",
    "                    ]\n",
    "                ),\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# model = \"RNN (GRU)\"\n",
    "# export_df = make_df_for_export(forecasts, model)\n",
    "# export_df.to_parquet(OUT_PATH / f\"for_market_eval_{model}.parquet\")\n",
    "# export_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_df[\"last_known_time\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_df[export_df[\"last_known_time\"] == \"2022-07-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lsh $OUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_df[\"last_known_time\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(export_df[\"company_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(export_df[\"last_known_time\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_df[\"step\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn it into an array of shape (n_splits, n_models, n_companies, n_timesteps, n_features, n_samples)\n",
    "forecasts_array = np.full(\n",
    "    (\n",
    "        len(forecasts),\n",
    "        len(ORDER_MODELS),\n",
    "        len(ORDER_COMPANIES),\n",
    "        HORIZON_FORECAST,\n",
    "        NUM_FEATURES,\n",
    "        N_SAMPLES or 1,\n",
    "    ),\n",
    "    # Make sure to use NaNs to indicate missing values in case we have a bug\n",
    "    fill_value=np.nan,\n",
    "    dtype=np.float64,\n",
    ")\n",
    "ground_truth_array = np.full(\n",
    "    (\n",
    "        len(forecasts),\n",
    "        len(ORDER_MODELS),\n",
    "        len(ORDER_COMPANIES),\n",
    "        HORIZON_FORECAST,\n",
    "        NUM_FEATURES,\n",
    "        # No samples, only one dimension\n",
    "    ),\n",
    "    fill_value=np.nan,\n",
    "    dtype=np.float64,\n",
    ")\n",
    "\n",
    "for split_num, split in enumerate(forecasts):\n",
    "    for model_num, model in enumerate(ORDER_MODELS):\n",
    "        for entry in split[model]:\n",
    "            company_num = ORDER_COMPANIES.index(entry.meta_data[\"companyid\"])\n",
    "\n",
    "            ground_truth_array[split_num, model_num, company_num, ...] = (\n",
    "                entry.ts_ground_truth.values()\n",
    "            )\n",
    "\n",
    "            fc = entry.ts_forecast\n",
    "            if fc is not None:\n",
    "                forecasts_array[split_num, model_num, company_num, ...] = (\n",
    "                    fc.all_values()\n",
    "                )\n",
    "\n",
    "                if np.isnan(\n",
    "                    forecasts_array[split_num, model_num, company_num, ...]\n",
    "                ).any():\n",
    "                    print(\n",
    "                        f\"NaNs in forecast for model '{model}' and company '{entry.meta_data['companyid']}'\"\n",
    "                    )\n",
    "\n",
    "forecasts_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(np.isnan(forecasts_array)) / forecasts_array.size * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(np.isnan(ground_truth_array)) / ground_truth_array.size * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the time and model where thes is NaN (first two dimensions)\n",
    "np.unique(np.argwhere(np.isnan(forecasts_array))[:, :2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORDER_MODELS[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array_path = OUT_PATH / \"data_array.pkl\"\n",
    "ground_truth_array_path = OUT_PATH / \"ground_truth_array.pkl\"\n",
    "\n",
    "if data_array_path.exists() and ground_truth_array_path.exists():\n",
    "    with open(data_array_path, \"rb\") as f:\n",
    "        forecasts_array = pickle.load(f)\n",
    "    with open(ground_truth_array_path, \"rb\") as f:\n",
    "        ground_truth_array = pickle.load(f)\n",
    "else:\n",
    "    with open(data_array_path, \"wb\") as f:\n",
    "        pickle.dump(forecasts_array, f)\n",
    "    with open(ground_truth_array_path, \"wb\") as f:\n",
    "        pickle.dump(ground_truth_array, f)\n",
    "\n",
    "forecasts_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = forecasts_array.mean(axis=-1, keepdims=True)[..., 0]\n",
    "# targets = ground_truth_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = targets[np.isfinite(preds)].reshape((40, 18, 2527, 4, 5))\n",
    "# preds = preds[np.isfinite(preds).reshape(preds.shape)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N_SAMPLES is None:  # forecasts are deterministic\n",
    "    preds = forecasts_array.squeeze(-1)\n",
    "    targets = ground_truth_array\n",
    "\n",
    "    fh_dim = -2\n",
    "    assert targets.shape[fh_dim] == HORIZON_FORECAST\n",
    "\n",
    "    def mae(pred: np.ndarray, truth: np.ndarray) -> np.ndarray:\n",
    "        return np.abs(pred - truth)\n",
    "\n",
    "    def mse(pred: np.ndarray, truth: np.ndarray) -> np.ndarray:\n",
    "        return np.square(pred - truth)\n",
    "\n",
    "    def rmse(pred: np.ndarray, truth: np.ndarray) -> np.ndarray:\n",
    "        overall = mse(pred, truth)\n",
    "        result = np.sqrt(overall.mean(fh_dim))  # mean over horizon\n",
    "        return np.stack([result] * overall.shape[fh_dim], axis=fh_dim)\n",
    "\n",
    "    def mape(\n",
    "        pred: np.ndarray, truth: np.ndarray, epsilon: float = 1.17e-06\n",
    "    ) -> np.ndarray:\n",
    "        return np.abs(pred - truth) / np.maximum(np.abs(truth), epsilon)\n",
    "\n",
    "    def rse(\n",
    "        pred: np.ndarray, truth: np.ndarray, epsilon: float = 1.17e-06\n",
    "    ) -> np.ndarray:\n",
    "        return np.square(pred - truth) / (\n",
    "            np.square(truth - np.expand_dims(truth.mean(fh_dim), fh_dim)) + epsilon\n",
    "        )\n",
    "\n",
    "    def smape(\n",
    "        pred: np.ndarray, truth: np.ndarray, epsilon: float = 1.17e-06\n",
    "    ) -> np.ndarray:\n",
    "        return np.abs(pred - truth) / np.maximum(\n",
    "            np.abs(pred), np.maximum(np.abs(truth), epsilon)\n",
    "        )\n",
    "\n",
    "    def r2(\n",
    "        pred: np.ndarray, truth: np.ndarray, epsilon: float = 1.17e-06\n",
    "    ) -> np.ndarray:\n",
    "        # mean over horizon\n",
    "        result = np.sum(np.square(pred - truth), axis=fh_dim) / (\n",
    "            np.sum(\n",
    "                np.square(truth - np.expand_dims(truth.mean(fh_dim), fh_dim)),\n",
    "                axis=fh_dim,\n",
    "            )\n",
    "            + epsilon\n",
    "        )\n",
    "        return 1 - np.stack([result] * pred.shape[fh_dim], axis=fh_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the metrics now all have shape (n_splits, n_models, n_companies, n_timesteps, n_features)\n",
    "\n",
    "if N_SAMPLES is None:\n",
    "    results = {\n",
    "        \"MAE\": mae(preds, targets),\n",
    "        \"MSE\": mse(preds, targets),\n",
    "        \"RMSE\": rmse(preds, targets),\n",
    "        \"MAPE\": mape(preds, targets),\n",
    "        \"RSE\": rse(preds, targets),\n",
    "        \"SMAPE\": smape(preds, targets),\n",
    "        \"R2\": r2(preds, targets),\n",
    "    }\n",
    "else:\n",
    "    negative_crps = crps_empirical_numpy(\n",
    "        np.moveaxis(forecasts_array, -1, 0), ground_truth_array\n",
    "    )\n",
    "    results = {\"nCRPS\": negative_crps}\n",
    "\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"nCRPS\" in results:\n",
    "    df_ncrps = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"split\": split_num,\n",
    "                \"model\": model,\n",
    "                \"metric\": \"nCRPS (avg)\",\n",
    "                \"value\": split[model_num, :, :, :].mean(axis=(0, 1, 2)).tolist(),\n",
    "            }\n",
    "            for split_num, split in enumerate(negative_crps)\n",
    "            for model_num, model in enumerate(ORDER_MODELS)\n",
    "        ]\n",
    "        + [\n",
    "            {\n",
    "                \"split\": split_num,\n",
    "                \"model\": model,\n",
    "                \"metric\": \"nCRPS (avg per feature)\",\n",
    "                \"value\": split[model_num, :, :, :].mean(axis=(0, 1)).tolist(),\n",
    "            }\n",
    "            for split_num, split in enumerate(negative_crps)\n",
    "            for model_num, model in enumerate(ORDER_MODELS)\n",
    "        ]\n",
    "        + [\n",
    "            {\n",
    "                \"split\": split_num,\n",
    "                \"model\": model,\n",
    "                \"metric\": \"nCRPS (avg per lookahead)\",\n",
    "                \"value\": split[model_num, :, :, :].mean(axis=(0, 2)).tolist(),\n",
    "            }\n",
    "            for split_num, split in enumerate(negative_crps)\n",
    "            for model_num, model in enumerate(ORDER_MODELS)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pd.to_pickle(df_ncrps, OUT_PATH / \"ncrps_df.pkl\")\n",
    "\n",
    "    df_ncrps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into a dataframe with columns split, model, metric, horizon_step, feature, value\n",
    "\n",
    "df_proper = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"split\": split_num,\n",
    "            \"model\": model,\n",
    "            \"metric\": name,\n",
    "            \"company_id\": ORDER_COMPANIES[company_idx],\n",
    "            \"feature\": FEATURE_NAMES[feature_idx],\n",
    "            \"horizon_step\": horizon_step,\n",
    "            \"value\": split[model_num, company_idx, horizon_step, feature_idx].item(),\n",
    "        }\n",
    "        for name, results_array in track(results.items())\n",
    "        for split_num, split in enumerate(results_array)\n",
    "        for model_num, model in enumerate(ORDER_MODELS)\n",
    "        for company_idx in range(len(ORDER_COMPANIES))\n",
    "        for horizon_step in range(HORIZON_FORECAST)\n",
    "        for feature_idx in range(NUM_FEATURES)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_proper.to_parquet(OUT_PATH / \"df_proper.parquet\")\n",
    "\n",
    "df_proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -sh {OUT_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_company_plot(df: pd.DataFrame) -> None:\n",
    "    # company_id = df[\"company_id\"].iloc[0]\n",
    "    # company_name = company_id_to_name[company_id]\n",
    "    grid = sns.relplot(\n",
    "        data=df.rename(columns={\"label\": \"Target Variates\"}).replace(\n",
    "            {\"Target Variates\": {\"forecast\": \"Forecast\", \"true\": \"Ground Truth\"}}\n",
    "        ),\n",
    "        col=\"variable\",\n",
    "        hue=\"Target Variates\",\n",
    "        col_wrap=3,\n",
    "        x=\"time\",\n",
    "        y=\"EUR\",\n",
    "        # style=\"split\",  # Too much information to be useful\n",
    "        # style=\"Target Variates\",  # Double legend to make it more obvious\n",
    "        kind=\"line\",\n",
    "        aspect=1.5,\n",
    "        facet_kws={\"sharey\": False, \"sharex\": True},\n",
    "        errorbar=(\"pi\", 68),\n",
    "        palette=\"colorblind\",\n",
    "    )\n",
    "    grid.figure.subplots_adjust(top=0.9)\n",
    "    grid.set_titles(\"{col_name}\")\n",
    "    grid.set(xlim=(df[\"time\"].min(), df[\"time\"].max()))\n",
    "    grid.set(xlabel=\"\")\n",
    "\n",
    "    # grid.figure.suptitle(f\"{model} predicting {company_name}\")\n",
    "\n",
    "    # Only have a legend about the label, not the split\n",
    "    # handles, labels = grid.axes[0].get_legend_handles_labels()\n",
    "    # grid.legend.remove()\n",
    "    # grid.axes[0].legend(handles[:2], labels[:2], title=\"Label\")\n",
    "    sns.move_legend(grid, \"upper center\", bbox_to_anchor=(0.775, 0.35))\n",
    "\n",
    "    sns.despine(bottom=True)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_FOR_ALL_MODELS = False\n",
    "\n",
    "is_first = True\n",
    "console = Console()\n",
    "for model in track(\n",
    "    list(forecasts[0].keys()),\n",
    "    description=\"Plotting for all models\",\n",
    "    console=console,\n",
    "):\n",
    "    break\n",
    "\n",
    "    model = \"RNN (GRU)\"\n",
    "\n",
    "    if (\n",
    "        df_models_per_window.loc[model, \"present in # windows\"]\n",
    "        < df_models_per_window[\"present in # windows\"].max()\n",
    "    ):\n",
    "        print(f\"WARNING: Skipping {model} because it is not present in all windows\")\n",
    "        continue\n",
    "\n",
    "    index = 50\n",
    "    interesting_company_ids = list(company_id_to_name.keys())[index : index + 20]\n",
    "\n",
    "    for company_id in track(\n",
    "        interesting_company_ids,\n",
    "        description=\"Plotting for each company\",\n",
    "        console=console,\n",
    "        disable=True,\n",
    "    ):\n",
    "        company_name = company_id_to_name[company_id]\n",
    "        data_company = make_df_for_company_results(\n",
    "            forecasts, model, include_companies=[company_id]\n",
    "        )\n",
    "        grid = make_company_plot(data_company)\n",
    "        grid.figure.show()\n",
    "\n",
    "        directory = OUT_PATH / \"plots\" / \"concrete_examples\" / model\n",
    "        directory.mkdir(exist_ok=True, parents=True)\n",
    "        plt.savefig(directory / f\"{company_id}-{company_name}.pdf\")\n",
    "        if is_first:\n",
    "            plt.show()\n",
    "            is_first = False\n",
    "\n",
    "            # if not PLOT_FOR_ALL_MODELS:\n",
    "            #     print(\"Limiting to the first company to be faster\")\n",
    "            #     break\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    if not PLOT_FOR_ALL_MODELS:\n",
    "        print(\"Limiting to the first model to be faster\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH / \"plots\" / \"concrete_examples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error aggregated over all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(base_path: Path, models: set[str] | None = None) -> pd.DataFrame:\n",
    "    df_all = pd.concat(\n",
    "        {\n",
    "            path.name: pd.read_pickle(\n",
    "                base_path / path.name / \"result_data\" / \"results.pkl\"\n",
    "            )\n",
    "            for path in base_path.iterdir()\n",
    "            if (path.is_dir() and path.name.isdigit())\n",
    "        },\n",
    "        names=[\"split\"],  # For the new index\n",
    "    )\n",
    "    df_all.reset_index(inplace=True)\n",
    "\n",
    "    ncrps_path = base_path / \"ncrps_df.pkl\"\n",
    "    if ncrps_path.exists():\n",
    "        df_ncrps = pd.read_pickle(ncrps_path)\n",
    "        df_all = pd.concat([df_all, df_ncrps], ignore_index=True)\n",
    "\n",
    "    df_all[\"split\"] = df_all[\"split\"].astype(int)\n",
    "    df_all = df_all.sort_values(by=[\"split\"])\n",
    "    if models is not None:\n",
    "        df_all = df_all[df_all[\"model\"].isin(models)]\n",
    "    else:\n",
    "        df_all = df_all[~df_all[\"model\"].isin(EXCLUDE)]\n",
    "    return df_all\n",
    "\n",
    "\n",
    "df_all = load_results(OUT_PATH)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH_AGGREGATED = OUT_PATH / \"plots\" / \"aggregated\"\n",
    "OUT_PATH_AGGREGATED.mkdir(exist_ok=True, parents=True)\n",
    "str(OUT_PATH_AGGREGATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_comparison(df_all, save_dir=OUT_PATH_AGGREGATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_avg_over_splits = (\n",
    "    melt_feature(df_all)\n",
    "    .groupby([\"model\", \"metric\", \"feature\"])  # not by split\n",
    "    .mean()\n",
    "    .drop(columns=[\"split\"])\n",
    "    .reset_index()\n",
    ")\n",
    "df_all_avg_over_splits.head()\n",
    "\n",
    "# plot_per_feature(df_all_avg_over_splits, save_dir=OUT_PATH_AGGREGATED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_over_time(\n",
    "    df: pd.DataFrame, save_dir: Path, postfix: str = \"\", show_metric: str = \"nCRPS\"\n",
    ") -> None:\n",
    "    df_lh_molten = melt_feature(df)\n",
    "    df_lh_molten.sort_values(by=[\"split\", \"model\"], inplace=True)\n",
    "    df_lh_molten = df_lh_molten[\n",
    "        df_lh_molten[\"metric\"] == f\"{show_metric} (avg per feature)\"\n",
    "    ]\n",
    "    df_lh_molten.drop(columns=[\"metric\"], inplace=True)\n",
    "    df_lh_molten.rename(columns={\"value\": show_metric}, inplace=True)\n",
    "\n",
    "    df_lh_molten[\"feature\"] = df_lh_molten[\"feature\"].apply(FEATURE_NAMES.__getitem__)\n",
    "\n",
    "    df_lh_molten[\"split\"] = df_lh_molten[\"split\"].apply(\n",
    "        split_index_to_start_time.__getitem__\n",
    "    )\n",
    "    df_lh_molten.rename(columns={\"split\": \"forecast start\"}, inplace=True)\n",
    "\n",
    "    save_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    plot: sns.FacetGrid = sns.relplot(\n",
    "        data=df_lh_molten,\n",
    "        x=\"forecast start\",\n",
    "        y=show_metric,\n",
    "        hue=\"model\",\n",
    "        style=\"model\",\n",
    "        col=\"feature\",\n",
    "        col_wrap=3,\n",
    "        kind=\"line\",\n",
    "        palette=palette,\n",
    "        facet_kws={\n",
    "            \"sharex\": False,\n",
    "            \"sharey\": True,  # Also show which features generally have the highest error:\n",
    "        },\n",
    "    )\n",
    "    xticks = sorted(list(split_index_to_start_time.values()))\n",
    "    plot.set_xticklabels(xticks, step=2, rotation=25, horizontalalignment=\"right\")\n",
    "    plt.subplots_adjust(hspace=0.25)\n",
    "    plt.savefig(save_dir / f\"comparison_error_over_time_per_feature{postfix}.pdf\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "plot_error_over_time(df_all, save_dir=OUT_PATH_AGGREGATED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison across directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH_CROSS = OUT_PATH.parent\n",
    "OUT_PATH_CROSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_det = load_results(\n",
    "    Path(\"forecast_baselines\")\n",
    "    / \"statics_True-revin_True-stride1_lb12-expanding-uq_False\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uq = load_results(\n",
    "    Path(\"forecast_baselines\")\n",
    "    / \"statics_True-revin_True-stride1_lb12-expanding-uq_True\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uq = df_uq[df_uq[\"model\"] != \"AutoTheta\"]  # too unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mae_ncrps = df_det[df_det[\"metric\"].str.contains(\"MAE\")].copy()\n",
    "\n",
    "df_mae_ncrps.set_index([\"split\", \"model\", \"metric\"], inplace=True)\n",
    "df_uq[\"metric\"] = df_uq[\"metric\"].str.replace(\"nCRPS\", \"MAE\", regex=True)\n",
    "probabilisitc_models = df_uq[\"model\"].unique().tolist()\n",
    "df_uq.set_index([\"split\", \"model\", \"metric\"], inplace=True)\n",
    "df_mae_ncrps.update(df_uq)\n",
    "df_mae_ncrps.reset_index(inplace=True)\n",
    "\n",
    "df_mae_ncrps[\"metric\"] = df_mae_ncrps[\"metric\"].str.replace(\n",
    "    \"MAE\", \"nCRPS/MAE\", regex=True\n",
    ")\n",
    "\n",
    "df_mae_ncrps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilisitc_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mae_ncrps[\"metric\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cross = pd.concat([df_det, df_mae_ncrps], ignore_index=True)\n",
    "df_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cross.dropna().groupby([\"model\"])[\"value\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cross.rename(columns={\"model\": \"Models\"}, inplace=True)\n",
    "\n",
    "order = [\n",
    "    \"Mean\",\n",
    "    \"ARMean(1)\",\n",
    "    \"ARMean(4)\",\n",
    "    \"ARMA(1,1)\",\n",
    "    \"ARMA(4,4)\",\n",
    "    \"ARIMA(4,1,4)\",\n",
    "    \"VARIMA(4,0,4)\",\n",
    "    \"VARIMA(4,1,4)\",\n",
    "    \"AutoARIMA\",\n",
    "    \"AutoTheta\",\n",
    "    \"Prophet\",\n",
    "    \"Linear Reg.\",\n",
    "    \"Random Forest\",\n",
    "    \"DLinear\",\n",
    "    \"NLinear\",\n",
    "    \"RNN (LSTM)\",\n",
    "    \"RNN (GRU)\",\n",
    "    \"Block RNN (LSTM)\",\n",
    "    \"Block RNN (GRU)\",\n",
    "    \"TCN\",\n",
    "    \"Transformer\",\n",
    "    \"TFT\",\n",
    "    \"N-BEATS\",\n",
    "    \"N-HiTS\",\n",
    "    \"TiDE\",\n",
    "    \"xLSTM-Mixer\",\n",
    "    \"Chronos-Bolt-Small\",\n",
    "    \"Chronos-Bolt-Base\",\n",
    "]\n",
    "MODEL_NOT_QUITE_SHORT_NAMES = {\n",
    "    \"Block RNN (GRU)\": \"Block GRU\",\n",
    "    \"Block RNN (LSTM)\": \"Block LSTM\",\n",
    "    \"RNN (GRU)\": \"GRU\",\n",
    "    \"RNN (LSTM)\": \"LSTM\",\n",
    "    \"Chronos-Bolt-Small\": \"Chronos Small\",\n",
    "    \"Chronos-Bolt-Base\": \"Chronos Base\",\n",
    "}\n",
    "for model in set(order):  # make a copy!\n",
    "    if model not in df_cross[\"Models\"].unique():\n",
    "        order.remove(model)\n",
    "df_cross[\"Models\"] = df_cross[\"Models\"].replace(MODEL_NOT_QUITE_SHORT_NAMES)\n",
    "order = [MODEL_NOT_QUITE_SHORT_NAMES.get(model, model) for model in order]\n",
    "\n",
    "df_cross[\"Models\"] = pd.Categorical(df_cross[\"Models\"], order)\n",
    "df_cross.sort_values(by=[\"Models\", \"metric\"], inplace=True)\n",
    "\n",
    "df_cross[\"metric\"] = (\n",
    "    df_cross[\"metric\"].str.replace(\"SMAPE\", \"sMAPE\").str.replace(\"R2\", \"R²\")\n",
    ")\n",
    "\n",
    "MODEL_SHORT_NAMES = {\n",
    "    \"ARMean(1)\": \"ARMean\\n(1)\",\n",
    "    \"ARMean(4)\": \"ARMean\\n(4)\",\n",
    "    \"ARMA(1,1)\": \"ARMA\\n(1,1)\",\n",
    "    \"ARMA(4,4)\": \"ARMA\\n(4,4)\",\n",
    "    \"ARIMA(4,1,4)\": \"ARIMA\\n(4,1,4)\",\n",
    "    \"VARIMA(4,0,4)\": \"VARIMA\\n(4,0,4)\",\n",
    "    \"VARIMA(4,1,4)\": \"VARIMA\\n(4,1,4)\",\n",
    "    \"Linear Reg.\": \"Linear\\nReg.\",\n",
    "    \"Random Forest\": \"Rand.\\nForest\",\n",
    "    \"AutoARIMA\": \"Auto\\nARIMA\",\n",
    "    \"AutoTheta\": \"Auto\\nTheta\",\n",
    "    \"Block GRU\": \"Block\\nGRU\",\n",
    "    \"Block LSTM\": \"Block\\nLSTM\",\n",
    "    \"Transformer\": \"Trans-\\nformer\",\n",
    "    \"xLSTM-Mixer\": \"xLSTM-\\nMixer\",\n",
    "    \"Chronos Small\": \"Chronos\\nSmall\",\n",
    "    \"Chronos Base\": \"Chronos\\nBase\",\n",
    "}\n",
    "probabilisitc_models = probabilisitc_models + [\n",
    "    after\n",
    "    for before, after in MODEL_NOT_QUITE_SHORT_NAMES.items()\n",
    "    if before in probabilisitc_models\n",
    "]\n",
    "probabilisitc_models = probabilisitc_models + [\n",
    "    after\n",
    "    for before, after in MODEL_SHORT_NAMES.items()\n",
    "    if before in probabilisitc_models\n",
    "]\n",
    "probabilisitc_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cross[\"Models\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://matplotlib.org/stable/users/explain/colors/colormaps.html#colormaps\n",
    "\n",
    "from matplotlib.cm import tab20, tab20b\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "custom_tab = ListedColormap(\n",
    "    tab20.colors + tab20b.colors[8:10] + tab20b.colors[1:2] + tab20b.colors[16:18], name=\"custom_tab\", N=25\n",
    ")\n",
    "sns.set_palette(sns.color_palette(custom_tab.colors))\n",
    "custom_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_metrics: List[str] = [\n",
    "#     \"MAE\",\n",
    "#     \"MAPE\",\n",
    "#     \"MSE\",\n",
    "#     \"R²\",\n",
    "#     \"RMSE\",\n",
    "#     \"RSE\",\n",
    "#     \"sMAPE\",\n",
    "#     \"sMAPE\",\n",
    "#     \"nCRPS/MAE\",\n",
    "# ]\n",
    "show_metrics: List[str] = [\"sMAPE\", \"MSE\"]\n",
    "# show_metrics: List[str] = [\"nCRPS/MAE\"]\n",
    "\n",
    "df_single = melt_avg(df_cross)\n",
    "df_single[\"metric\"] = df_single[\"metric\"].str.split(\" \", n=2, expand=True)[0]\n",
    "\n",
    "df_single.sort_values(by=[\"metric\", \"Models\"], inplace=True)\n",
    "df_single = df_single.reset_index()\n",
    "\n",
    "df_single_plot = df_single[df_single[\"metric\"].isin(show_metrics)].copy()\n",
    "df_single_plot[\"Models\"] = df_single_plot[\"Models\"].replace(MODEL_SHORT_NAMES)\n",
    "\n",
    "# add \"*\" to the model it is is in probabilisitc_models\n",
    "if \"nCRPS/MAE\" in show_metrics:\n",
    "    df_single_plot[\"Models\"] = df_single_plot[\"Models\"].apply(\n",
    "        lambda x: f\"{x}*\" if x not in probabilisitc_models else x\n",
    "    )\n",
    "\n",
    "plot: sns.FacetGrid = sns.catplot(\n",
    "    data=df_single_plot,\n",
    "    x=\"Models\",\n",
    "    y=\"value\",\n",
    "    hue=\"Models\",\n",
    "    col=\"metric\",\n",
    "    col_wrap=1,\n",
    "    kind=\"bar\",\n",
    "    # palette=custom_tab,\n",
    "    sharex=True,\n",
    "    sharey=False,\n",
    "    legend=False,\n",
    "    aspect=4.5,\n",
    ")\n",
    "plot.tick_params(labelsize=\"small\")\n",
    "plot.set_titles(\"{col_name}\")\n",
    "for ax in plot.axes.flat:\n",
    "    title = ax.title.get_text()\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_title(\"\")\n",
    "\n",
    "    # Make vertically dashed lines to the right of the models\n",
    "    at = [7, 9, 22]\n",
    "    for i in at:\n",
    "        ax.axvline(i + 0.5, color=\"black\", linestyle=\"--\", linewidth=1.0, alpha=0.5)\n",
    "\n",
    "# Section labels between teh dashed lines (as titles on top)\n",
    "labels = [\"Local\", \"Global\", \"Deep Learning\", \"Pretrained\"]\n",
    "first_ax = plot.axes.flat[0]\n",
    "for i, last_i, label in zip(\n",
    "    at + [df_single_plot[\"Models\"].unique().size - 1], [-1] + at, labels\n",
    "):\n",
    "    first_ax.text(\n",
    "        i - (i - last_i) / 2 + 0.5,\n",
    "        # 0.45,\n",
    "        1.81,\n",
    "        label,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        alpha=0.75,\n",
    "        fontsize=\"smaller\",\n",
    "    )\n",
    "\n",
    "# first_ax.set_ylim(None, 0.3)\n",
    "\n",
    "suffix = \"nCRPS\" if \"nCRPS/MAE\" in show_metrics else \"det\"\n",
    "plt.savefig(OUT_PATH_CROSS / f\"comparison_avg_paper_{suffix}.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics: List[str] = [\"sMAPE\", \"MSE\", \"nCRPS/MAE\"]\n",
    "\n",
    "df_lh_molten = melt_lookahead(df_cross)\n",
    "df_lh_molten = df_lh_molten[\n",
    "    df_lh_molten[\"metric\"].str.split(\" \", n=2, expand=True)[0].isin(show_metrics)\n",
    "]\n",
    "df_lh_molten[\"look-ahead\"] = df_lh_molten[\"look-ahead\"].astype(\"str\")\n",
    "df_lh_molten[\"metric\"] = df_lh_molten[\"metric\"].str.split(\" \", n=2, expand=True)[0]\n",
    "# Fix the order of the models\n",
    "df_lh_molten[\"metric\"] = pd.Categorical(df_lh_molten[\"metric\"], show_metrics)\n",
    "\n",
    "df_lh_molten.rename(columns={\"look-ahead\": \"quarters look-ahead\"}, inplace=True)\n",
    "\n",
    "plot: sns.FacetGrid = sns.relplot(\n",
    "    data=df_lh_molten.dropna(),\n",
    "    x=\"quarters look-ahead\",\n",
    "    y=\"value\",\n",
    "    hue=\"Models\",\n",
    "    style=\"Models\",\n",
    "    col=\"metric\",\n",
    "    kind=\"line\",\n",
    "    # palette=custom_tab,\n",
    "    facet_kws={\"sharey\": False},\n",
    ")\n",
    "plot.set_titles(\"{col_name}\")\n",
    "for ax in plot.axes.flat:\n",
    "    title = ax.title.get_text()\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_title(\"\")\n",
    "sns.move_legend(plot, \"center right\", bbox_to_anchor=(1.2, 0.5), ncol=2)\n",
    "plot.set(\n",
    "    xlim=(\n",
    "        df_lh_molten[\"quarters look-ahead\"].min(),\n",
    "        df_lh_molten[\"quarters look-ahead\"].max(),\n",
    "    )\n",
    ")\n",
    "# plot.set(ylim=(0, None))\n",
    "plt.subplots_adjust(wspace=0.45)\n",
    "# plot.tight_layout()  # Adjust the subplot layout\n",
    "plt.savefig(OUT_PATH_CROSS / \"comparison_lookahead_paper.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index_to_start_time = {\n",
    "    0: \"2013 Q1\",\n",
    "    1: \"2013 Q2\",\n",
    "    2: \"2013 Q3\",\n",
    "    3: \"2013 Q4\",\n",
    "    4: \"2014 Q1\",\n",
    "    5: \"2014 Q2\",\n",
    "    6: \"2014 Q3\",\n",
    "    7: \"2014 Q4\",\n",
    "    8: \"2015 Q1\",\n",
    "    9: \"2015 Q2\",\n",
    "    10: \"2015 Q3\",\n",
    "    11: \"2015 Q4\",\n",
    "    12: \"2016 Q1\",\n",
    "    13: \"2016 Q2\",\n",
    "    14: \"2016 Q3\",\n",
    "    15: \"2016 Q4\",\n",
    "    16: \"2017 Q1\",\n",
    "    17: \"2017 Q2\",\n",
    "    18: \"2017 Q3\",\n",
    "    19: \"2017 Q4\",\n",
    "    20: \"2018 Q1\",\n",
    "    21: \"2018 Q2\",\n",
    "    22: \"2018 Q3\",\n",
    "    23: \"2018 Q4\",\n",
    "    24: \"2019 Q1\",\n",
    "    25: \"2019 Q2\",\n",
    "    26: \"2019 Q3\",\n",
    "    27: \"2019 Q4\",\n",
    "    28: \"2020 Q1\",\n",
    "    29: \"2020 Q2\",\n",
    "    30: \"2020 Q3\",\n",
    "    31: \"2020 Q4\",\n",
    "    32: \"2021 Q1\",\n",
    "    33: \"2021 Q2\",\n",
    "    34: \"2021 Q3\",\n",
    "    35: \"2021 Q4\",\n",
    "    36: \"2022 Q1\",\n",
    "    37: \"2022 Q2\",\n",
    "    38: \"2022 Q3\",\n",
    "    39: \"2022 Q4\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lh_molten = melt_feature(df_cross)\n",
    "\n",
    "show_metric: str = \"nCRPS/MAE\"\n",
    "# show_metric: str = \"nCRPS\"\n",
    "\n",
    "df_lh_molten.sort_values(by=[\"split\", \"Models\"], inplace=True)\n",
    "df_lh_molten = df_lh_molten[\n",
    "    df_lh_molten[\"metric\"] == f\"{show_metric} (avg per feature)\"\n",
    "]\n",
    "df_lh_molten.drop(columns=[\"metric\"], inplace=True)\n",
    "df_lh_molten.rename(\n",
    "    columns={\"value\": show_metric, \"forecast start\": \"Forecast Start\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df_lh_molten[\"feature\"] = df_lh_molten[\"feature\"].apply(FEATURE_NAMES.__getitem__)\n",
    "\n",
    "df_lh_molten[\"Forecast Start\"] = df_lh_molten[\"split\"].apply(\n",
    "    split_index_to_start_time.__getitem__\n",
    ")\n",
    "\n",
    "# df_lh_molten = df_lh_molten[df_lh_molten[\"Models\"] != \"Linear Reg.\"]\n",
    "\n",
    "plot: sns.FacetGrid = sns.relplot(\n",
    "    data=df_lh_molten,\n",
    "    x=\"Forecast Start\",\n",
    "    y=show_metric,\n",
    "    hue=\"Models\",\n",
    "    style=\"Models\",\n",
    "    col=\"feature\",\n",
    "    col_wrap=3,\n",
    "    kind=\"line\",\n",
    "    # palette=custom_tab,\n",
    "    facet_kws={\n",
    "        \"sharex\": False,\n",
    "        \"sharey\": False,\n",
    "    },\n",
    "    err_kws=dict(\n",
    "        alpha=0.05\n",
    "    ),  # Also show which features generally have the highest error\n",
    "    aspect=1.75,\n",
    ")\n",
    "plot.set_titles(\"{col_name}\")\n",
    "\n",
    "xticks = sorted(split_index_to_start_time.values())\n",
    "xticks_before = list(xticks)\n",
    "xticks = [\n",
    "    item.split(\" \", maxsplit=1)[0] if item.endswith(\"Q1\") else \"\" for item in xticks\n",
    "]\n",
    "plot.set_xticklabels(xticks, rotation=0, horizontalalignment=\"center\")\n",
    "\n",
    "# from matplotlib.ticker import MultipleLocator, AutoMinorLocator, IndexLocator\n",
    "# for ax in plot.axes.flat:\n",
    "#     ax.xaxis.set_minor_locator(IndexLocator(2, 1))\n",
    "#     ax.xaxis.set_major_locator(IndexLocator(4, 0))\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "ymin, ymax = 0.0, 0.6\n",
    "for ax in plot.axes.flat:\n",
    "    covid = xticks_before.index(\"2020 Q1\")\n",
    "    # ax.vlines(\n",
    "    #     covid + 0.5,\n",
    "    #     ymin,\n",
    "    #     ymax,\n",
    "    #     color=\"black\",\n",
    "    #     linestyle=\"--\",\n",
    "    #     label=\"COVID-19\",\n",
    "    # )\n",
    "    ax.add_patch(\n",
    "        patches.Rectangle((covid - 4, ymin), width=8, height=ymax, fill=True, alpha=0.2)\n",
    "    )\n",
    "\n",
    "# Label COVID in the upper left plot\n",
    "first_ax = plot.axes.flat[0]\n",
    "first_ax.text(\n",
    "    covid,\n",
    "    0.45,\n",
    "    \"pandemic\",\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    alpha=1.0,\n",
    "    fontsize=\"smaller\",\n",
    ")\n",
    "\n",
    "plot.set(ylim=(ymin, ymax), xlim=(0, len(xticks_before)))\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "sns.move_legend(\n",
    "    plot,\n",
    "    \"lower right\",\n",
    "    bbox_to_anchor=(0.91, 0.12),\n",
    "    ncol=3,\n",
    "    fontsize=\"medium\",\n",
    "    title_fontsize=\"larger\",\n",
    ")\n",
    "\n",
    "plt.savefig(\n",
    "    OUT_PATH_CROSS / \"comparison_error_over_time_per_feature_paper.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_avg_over_splits = (\n",
    "    melt_feature(df_cross)\n",
    "    .groupby([\"Models\", \"metric\", \"feature\"], observed=True)  # not by split\n",
    "    .mean(numeric_only=True)\n",
    "    .drop(columns=[\"split\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "selected_metric: str = \"nCRPS/MAE\"\n",
    "title: str = f\"{selected_metric} per model and feature\"\n",
    "\n",
    "df_feat_molten_selected = melt_feature(\n",
    "    df_all_avg_over_splits[\n",
    "        df_all_avg_over_splits[\"metric\"] == f\"{selected_metric} (avg per feature)\"\n",
    "    ]\n",
    ")\n",
    "df_feat_molten_selected[\"feature\"] = (\n",
    "    df_feat_molten_selected[\"feature\"]\n",
    "    .apply(FEATURE_NAMES.__getitem__)\n",
    "    .replace(\"Cash from Operations\", \"Cash from  \\nOperations\")\n",
    ")\n",
    "\n",
    "df_feat_molten_selected = df_feat_molten_selected[\n",
    "    ~df_feat_molten_selected[\"Models\"].isin({\"Linear Reg.\", \"Chronos Base\", \"Chronos Small\"})\n",
    "]\n",
    "\n",
    "heatmap_data = (\n",
    "    df_feat_molten_selected.reset_index()\n",
    "    .pivot(columns=\"feature\", index=\"Models\", values=\"value\")\n",
    "    .sort_values(by=[\"feature\"], axis=\"columns\")\n",
    ")\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    g = sns.JointGrid(\n",
    "        data=df_feat_molten_selected,\n",
    "        x=\"feature\",\n",
    "        y=\"Models\",\n",
    "        hue=\"value\",\n",
    "        marginal_ticks=True,\n",
    "        height=8,\n",
    "        # ratio=10,\n",
    "    )\n",
    "\n",
    "    # Create an inset legend for the histogram colorbar\n",
    "    # format: (left, bottom, width, height)\n",
    "    cax = g.figure.add_axes([0.86, 0.83, 0.015, 0.12])\n",
    "\n",
    "    # Add the joint and marginal histogram plots\n",
    "    h = sns.heatmap(\n",
    "        data=heatmap_data,\n",
    "        ax=g.ax_joint,\n",
    "        cbar_ax=cax,\n",
    "        annot=True,\n",
    "        fmt=\".3f\",\n",
    "        annot_kws=dict(fontsize=\"x-small\"),\n",
    "        xticklabels=True,\n",
    "        yticklabels=True,\n",
    "        # cmap=\"rocket_r\",\n",
    "        cmap=\"flare\",\n",
    "    )\n",
    "    cmap = cax.collections[1].get_cmap()\n",
    "    cmap_norm = cax.collections[1].norm\n",
    "    h.set_xticklabels(h.get_xticklabels(), rotation=30, horizontalalignment=\"right\")\n",
    "\n",
    "    barv_data = df_feat_molten_selected.groupby([\"feature\"])[\"value\"].mean().to_numpy()\n",
    "    g.ax_marg_x.bar(\n",
    "        g.ax_joint.get_xticks(),\n",
    "        barv_data,\n",
    "        align=\"center\",\n",
    "        color=cmap(cmap_norm(barv_data)),\n",
    "    )\n",
    "    g.ax_marg_x.yaxis.set_ticks_position(\"left\")\n",
    "    # g.ax_marg_x.yaxis.set_ticks([0, 0.2])\n",
    "\n",
    "    barh_data = (\n",
    "        df_feat_molten_selected.groupby([\"Models\"], observed=True)[\"value\"]\n",
    "        .mean()\n",
    "        .to_numpy()\n",
    "    )\n",
    "    g.ax_marg_y.barh(\n",
    "        g.ax_joint.get_yticks(),\n",
    "        barh_data,\n",
    "        align=\"center\",\n",
    "        color=cmap(cmap_norm(barh_data)),\n",
    "    )\n",
    "    g.ax_marg_y.xaxis.set_ticks_position(\"bottom\")\n",
    "    g.ax_marg_y.xaxis.set_ticks([0, 0.2])\n",
    "\n",
    "    g.ax_joint.set_ylabel(\"\")\n",
    "    g.ax_joint.set_xlabel(\"\")\n",
    "\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    # plt.suptitle(title)\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.savefig(OUT_PATH_CROSS / \"error_per_feature.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate performance comparison tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(data, fun: str = \"max\"):\n",
    "    \"\"\"\n",
    "    highlight the maximum in a Series or DataFrame + the runner-up\n",
    "    \"\"\"\n",
    "    attr_max = \"textbf: --rwrap;\"\n",
    "    attr_runner_up = \"underline: --rwrap;\"\n",
    "\n",
    "    # remove % and cast to float\n",
    "    data = (\n",
    "        data.str.split(\"±\")\n",
    "        .apply(lambda x: x[0])\n",
    "        .apply(lambda x: float(\"nan\") if \"nan\" in x else x)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        max_value = getattr(data, fun)()\n",
    "        is_max = data == max_value\n",
    "        runner_up_value = getattr(data[data != max_value], fun)()  # can be NaN\n",
    "        is_runner_up = (\n",
    "            [False] * len(data)\n",
    "            if np.isnan(runner_up_value)\n",
    "            else data == runner_up_value\n",
    "        )\n",
    "        return np.where(\n",
    "            is_max, attr_max, np.where(is_runner_up, attr_runner_up, \"\")\n",
    "        ).tolist()\n",
    "    else:\n",
    "        max_value = getattr(getattr(data, fun)(), fun)()\n",
    "        is_max = data == max_value\n",
    "        runner_up_value = getattr(getattr(data[data != max_value], fun)(), fun)()\n",
    "        is_runner_up = (\n",
    "            [False] * len(data.columns)\n",
    "            if np.isnan(runner_up_value)\n",
    "            else data == runner_up_value\n",
    "        )\n",
    "        return pd.DataFrame(\n",
    "            np.where(is_max, attr_max, np.where(is_runner_up, attr_runner_up, \"\")),\n",
    "            index=data.index,\n",
    "            columns=data.columns,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single = melt_avg(df_cross)\n",
    "# df_single = melt_avg_for_human(df_cross)\n",
    "\n",
    "df_single[\"metric\"] = df_single[\"metric\"].str.split(\" \", n=2, expand=True)[0]\n",
    "df_single.sort_values(by=[\"metric\", \"Models\"], inplace=True)\n",
    "df_single = df_single.reset_index()\n",
    "\n",
    "dfc = (\n",
    "    df_single.groupby([\"Models\", \"metric\"], observed=True)\n",
    "    .agg({\"value\": [\"mean\", \"std\"]})\n",
    "    .droplevel(0, axis=\"columns\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "dfc[\"value\"] = (\n",
    "    dfc[\"mean\"].apply(lambda x: f\"{x:0>2.3f}\")\n",
    "    + \"±\"\n",
    "    + dfc[\"std\"].apply(lambda x: f\"{x:.2f}\")\n",
    ")\n",
    "del dfc[\"mean\"]\n",
    "del dfc[\"std\"]\n",
    "\n",
    "df = dfc.pivot(index=\"Models\", columns=\"metric\", values=\"value\")\n",
    "\n",
    "df = df[\n",
    "    [\n",
    "        \"MAE\",\n",
    "        \"MSE\",\n",
    "        \"RMSE\",\n",
    "        \"MAPE\",\n",
    "        \"RSE\",\n",
    "        \"sMAPE\",\n",
    "        \"R²\",\n",
    "        \"nCRPS/MAE\",\n",
    "    ]\n",
    "]\n",
    "df.columns = [\n",
    "    f\"{metric} (\\\\textdownarrow)\" if metric != \"R²\" else metric for metric in df.columns\n",
    "]\n",
    "r2_new = \"R\\\\textsuperscript{2} (\\\\textuparrow)\"\n",
    "df.columns = df.columns.str.replace(\"R²\", r2_new)\n",
    "\n",
    "df.columns = df.columns.str.replace(\"nCRPS/MAE\", \"nCRPS\")\n",
    "\n",
    "styled = df.style.apply(\n",
    "    highlight, fun=\"min\", subset=list(set(df.columns.tolist()) - {r2_new})\n",
    ").apply(highlight, fun=\"max\", subset=[r2_new])\n",
    "\n",
    "print(\n",
    "    styled.to_latex(\n",
    "        position_float=\"centering\",\n",
    "        hrules=True,\n",
    "        position=\"th\",\n",
    "        label=\"tab:comparison_overall\",\n",
    "        caption=\"Comparison of average performance of the models measured by different metrics. The best is marked as \\\\textbf{bold} and the runner-up as \\\\underline{underlined}.\",\n",
    "    )\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With proper std dev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_detailed_results(\n",
    "    base_path: Path, models: set[str] | None = None\n",
    ") -> pd.DataFrame:\n",
    "    df_all = pd.read_parquet(base_path / \"df_proper.parquet\")\n",
    "\n",
    "    if models is not None:\n",
    "        df_all = df_all[df_all[\"model\"].isin(models)]\n",
    "    else:\n",
    "        df_all = df_all[~df_all[\"model\"].isin(EXCLUDE)]\n",
    "\n",
    "    return df_all\n",
    "\n",
    "\n",
    "df_proper = pd.concat(\n",
    "    [\n",
    "        load_detailed_results(\n",
    "            Path(\"forecast_baselines\")\n",
    "            / \"statics_True-revin_True-stride1_lb12-expanding-uq_False\",\n",
    "        ),\n",
    "        load_detailed_results(\n",
    "            Path(\"forecast_baselines\")\n",
    "            / \"statics_True-revin_True-stride1_lb12-expanding-uq_True\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_proper = df_proper.rename(columns={\"model\": \"Models\"})\n",
    "\n",
    "# df_proper[\"Models\"] = pd.Categorical(df_proper[\"Models\"], order)\n",
    "df_proper = df_proper.sort_values(by=[\"Models\", \"metric\"])  # This is slow!\n",
    "\n",
    "df_proper[\"metric\"] = (\n",
    "    df_proper[\"metric\"].str.replace(\"SMAPE\", \"sMAPE\").str.replace(\"R2\", \"R²\")\n",
    ")\n",
    "\n",
    "df_proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel = df_proper.query(\"metric == 'RSE' and Models == 'ARMA(4,4)'\")\n",
    "# sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = (\n",
    "    df_proper.groupby([\"Models\", \"metric\"], observed=True)\n",
    "    .agg({\"value\": [\"mean\", \"std\"]})\n",
    "    .droplevel(0, axis=\"columns\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "assert not dfc.empty\n",
    "dfc[\"value\"] = (\n",
    "    dfc[\"mean\"].apply(lambda x: f\"{x:0>2.3f}\")\n",
    "    + \"±\"\n",
    "    + dfc[\"std\"].apply(lambda x: f\"{x:.2f}\")\n",
    ")\n",
    "del dfc[\"mean\"]\n",
    "del dfc[\"std\"]\n",
    "\n",
    "df = dfc.pivot(index=\"Models\", columns=\"metric\", values=\"value\")\n",
    "\n",
    "df.loc[df[\"nCRPS\"].isna(), \"nCRPS\"] = df.loc[df[\"nCRPS\"].isna(), \"MAE\"]\n",
    "\n",
    "df = df[\n",
    "    [\n",
    "        \"MAE\",\n",
    "        \"MSE\",\n",
    "        \"RMSE\",\n",
    "        \"MAPE\",\n",
    "        \"RSE\",\n",
    "        \"sMAPE\",\n",
    "        \"R²\",\n",
    "        \"nCRPS\",\n",
    "    ]\n",
    "]\n",
    "df.columns = [\n",
    "    f\"{metric} (\\\\textdownarrow)\" if metric != \"R²\" else metric for metric in df.columns\n",
    "]\n",
    "r2_new = \"R\\\\textsuperscript{2} (\\\\textuparrow)\"\n",
    "df.columns = df.columns.str.replace(\"R²\", r2_new)\n",
    "\n",
    "df.columns = df.columns.str.replace(\"nCRPS/MAE\", \"nCRPS\")\n",
    "\n",
    "styled = df.style.apply(\n",
    "    highlight, fun=\"min\", subset=list(set(df.columns.tolist()) - {r2_new})\n",
    ").apply(highlight, fun=\"max\", subset=[r2_new])\n",
    "\n",
    "print(\n",
    "    styled.to_latex(\n",
    "        position_float=\"centering\",\n",
    "        hrules=True,\n",
    "        position=\"th\",\n",
    "        label=\"tab:comparison_overall\",\n",
    "        caption=\"Comparison of average performance of the models measured by different metrics. The best is marked as \\\\textbf{bold} and the runner-up as \\\\underline{underlined}.\",\n",
    "    )\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricted to human eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_eval_companies = np.loadtxt(\"human_eval_companies.csv\", delimiter=\",\")\n",
    "human_eval_companies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_as_human = df_proper\n",
    "df_as_human = df_as_human[df_as_human[\"company_id\"].isin(human_eval_companies)]\n",
    "df_as_human = df_as_human.drop(columns=[\"feature\", \"horizon_step\"])\n",
    "df_as_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emulate the averaging over all companies\n",
    "df_as_human_avg = (\n",
    "    df_as_human.groupby([\"Models\", \"metric\", \"split\"], observed=True)\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "df_as_human_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = (\n",
    "    df_as_human_avg.groupby([\"Models\", \"metric\"], observed=True)\n",
    "    .agg({\"value\": [\"mean\", \"std\"]})\n",
    "    .droplevel(0, axis=\"columns\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "dfc[\"value\"] = (\n",
    "    dfc[\"mean\"].apply(lambda x: f\"{x:0>2.3f}\")\n",
    "    + \"±\"\n",
    "    + dfc[\"std\"].apply(lambda x: f\"{x:.2f}\")\n",
    ")\n",
    "del dfc[\"mean\"]\n",
    "del dfc[\"std\"]\n",
    "\n",
    "df = dfc.pivot(index=\"Models\", columns=\"metric\", values=\"value\")\n",
    "\n",
    "df.loc[df[\"nCRPS\"].isna(), \"nCRPS\"] = df.loc[df[\"nCRPS\"].isna(), \"MAE\"]\n",
    "\n",
    "df = df[\n",
    "    [\n",
    "        \"MAE\",\n",
    "        \"MSE\",\n",
    "        \"RMSE\",\n",
    "        \"MAPE\",\n",
    "        \"RSE\",\n",
    "        \"sMAPE\",\n",
    "        \"R²\",\n",
    "        \"nCRPS\",\n",
    "    ]\n",
    "]\n",
    "df.columns = [\n",
    "    f\"{metric} (\\\\textdownarrow)\" if metric != \"R²\" else metric for metric in df.columns\n",
    "]\n",
    "r2_new = \"R\\\\textsuperscript{2} (\\\\textuparrow)\"\n",
    "df.columns = df.columns.str.replace(\"R²\", r2_new)\n",
    "\n",
    "df.columns = df.columns.str.replace(\"nCRPS/MAE\", \"nCRPS\")\n",
    "\n",
    "styled = df.style.apply(\n",
    "    highlight, fun=\"min\", subset=list(set(df.columns.tolist()) - {r2_new})\n",
    ").apply(highlight, fun=\"max\", subset=[r2_new])\n",
    "\n",
    "print(\n",
    "    styled.to_latex(\n",
    "        position_float=\"centering\",\n",
    "        hrules=True,\n",
    "        position=\"th\",\n",
    "        label=\"tab:comparison_overall\",\n",
    "        caption=\"Comparison of average performance of the models measured by different metrics. The best is marked as \\\\textbf{bold} and the runner-up as \\\\underline{underlined}.\",\n",
    "    )\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with and w/o RevIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = 12\n",
    "revin_with = load_results(\n",
    "    Path(\"forecast_baselines\")\n",
    "    / f\"statics_True-revin_True-stride1_lb{lb}-expanding-uq_True\"\n",
    ")\n",
    "revin_wo = load_results(\n",
    "    Path(\"forecast_baselines\")\n",
    "    / f\"statics_True-revin_False-stride1_lb{lb}-expanding-uq_True\"\n",
    ")\n",
    "revin_with.shape == revin_wo.shape\n",
    "revin_with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.concat(\n",
    "        {\n",
    "            \"with\": melt_avg(revin_with),\n",
    "            \"without\": melt_avg(revin_wo),\n",
    "        },\n",
    "        names=[\"RevIN\"],\n",
    "    )\n",
    "    .reset_index()\n",
    "    .drop(\"level_1\", axis=\"columns\")\n",
    ")\n",
    "df = df.rename(columns={\"model\": \"Models\"})\n",
    "df[\"Models\"] = pd.Categorical(df[\"Models\"], order)\n",
    "df = df.sort_values(by=[\"Models\", \"metric\"])\n",
    "df = df[df[\"metric\"] == \"nCRPS (avg)\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"RevIN\"] == \"with\", \"metric\"] = \"With RevIN\"\n",
    "df.loc[df[\"RevIN\"] == \"without\", \"metric\"] = \"Without RevIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = (\n",
    "    df.groupby([\"Models\", \"metric\"], observed=True)\n",
    "    .agg({\"value\": [\"mean\", \"std\"]})\n",
    "    .droplevel(0, axis=\"columns\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "dfc[\"value\"] = (\n",
    "    dfc[\"mean\"].apply(lambda x: f\"{x:0>2.3f}\")\n",
    "    + \"±\"\n",
    "    + dfc[\"std\"].apply(lambda x: f\"{x:.2f}\")\n",
    ")\n",
    "del dfc[\"mean\"]\n",
    "del dfc[\"std\"]\n",
    "\n",
    "df = dfc.pivot(index=\"Models\", columns=\"metric\", values=\"value\")\n",
    "\n",
    "df.dropna(inplace=True, axis=\"index\")\n",
    "\n",
    "revin_with = df[\"With RevIN\"].str.split(\"±\", expand=True)[0].astype(float)\n",
    "revin_wo = df[\"Without RevIN\"].str.split(\"±\", expand=True)[0].astype(float)\n",
    "df[\"Improvement\"] = (100 * (revin_wo - revin_with) / revin_wo).apply(\n",
    "    lambda x: f\"{x:.2f}\\%\"\n",
    ")\n",
    "\n",
    "df = df[[\"Without RevIN\", \"With RevIN\", \"Improvement\"]]  # fix the order\n",
    "\n",
    "print(\n",
    "    df.style.to_latex(\n",
    "        position_float=\"centering\",\n",
    "        hrules=True,\n",
    "        position=\"th\",\n",
    "        label=\"tab:revin_vs_without\",\n",
    "        caption=\"A comparison showing the benefit of RevIN.\",\n",
    "    )\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare w/ and w/o statics features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = 12\n",
    "statics_with = load_results(\n",
    "    Path(\"forecast_baselines\")\n",
    "    / f\"statics_True-revin_True-stride1_lb{lb}-expanding-uq_True\"\n",
    ")\n",
    "statics_wo = load_results(\n",
    "    Path(\"forecast_baselines\")\n",
    "    / f\"statics_False-revin_True-stride1_lb{lb}-expanding-uq_True\"\n",
    ")\n",
    "statics_with.shape == statics_wo.shape\n",
    "statics_with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statics_wo[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(statics_with[\"model\"].unique()), len(statics_wo[\"model\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.concat(\n",
    "        {\n",
    "            \"with\": melt_avg(statics_with),\n",
    "            \"without\": melt_avg(statics_wo),\n",
    "        },\n",
    "        names=[\"Statics\"],\n",
    "    )\n",
    "    .reset_index()\n",
    "    .drop(\"level_1\", axis=\"columns\")\n",
    ")\n",
    "df = df.rename(columns={\"model\": \"Models\"})\n",
    "# df[\"Models\"] = pd.Categorical(df[\"Models\"], order)\n",
    "df = df.sort_values(by=[\"Models\", \"metric\"])\n",
    "df = df[df[\"metric\"] == \"nCRPS (avg)\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Models\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only compare those models that can actually house static features\n",
    "df = df[\n",
    "    df[\"Models\"].isin(\n",
    "        {\n",
    "            \"Linear Reg.\",\n",
    "            \"Random Forest\",\n",
    "            \"DLinear\",\n",
    "            \"NLinear\",\n",
    "            \"TFT\",\n",
    "            \"TiDE\",\n",
    "        }\n",
    "    )\n",
    "]\n",
    "df[\"Models\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Statics\"] == \"with\", \"metric\"] = \"With Statics\"\n",
    "df.loc[df[\"Statics\"] == \"without\", \"metric\"] = \"Without Statics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = (\n",
    "    df.groupby([\"Models\", \"metric\"], observed=True)\n",
    "    .agg({\"value\": [\"mean\", \"std\"]})\n",
    "    .droplevel(0, axis=\"columns\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "dfc[\"value\"] = (\n",
    "    dfc[\"mean\"].apply(lambda x: f\"{x:0>2.3f}\")\n",
    "    + \"±\"\n",
    "    + dfc[\"std\"].apply(lambda x: f\"{x:.2f}\")\n",
    ")\n",
    "del dfc[\"mean\"]\n",
    "del dfc[\"std\"]\n",
    "\n",
    "df = dfc.pivot(index=\"Models\", columns=\"metric\", values=\"value\")\n",
    "\n",
    "df.dropna(inplace=True, axis=\"index\")\n",
    "\n",
    "revin_with = df[\"With Statics\"].str.split(\"±\", expand=True)[0].astype(float)\n",
    "revin_wo = df[\"Without Statics\"].str.split(\"±\", expand=True)[0].astype(float)\n",
    "df[\"Improvement\"] = (100 * (revin_wo - revin_with) / revin_wo).apply(\n",
    "    lambda x: f\"{x:.2f}\\%\"\n",
    ")\n",
    "\n",
    "df = df[[\"Without Statics\", \"With Statics\", \"Improvement\"]]  # fix the order\n",
    "\n",
    "print(\n",
    "    df.style.to_latex(\n",
    "        position_float=\"centering\",\n",
    "        hrules=True,\n",
    "        position=\"th\",\n",
    "        label=\"tab:benefit_of_statics\",\n",
    "        caption=\"A comparison showing the benefit of incorporating static features.\",\n",
    "    )\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
